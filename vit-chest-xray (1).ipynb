{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":2169393,"sourceType":"datasetVersion","datasetId":1302315}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torch torchvision --index-url https://download.pytorch.org/whl/cu117\n!pip install transformers datasets timm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T15:33:22.747755Z","iopub.execute_input":"2025-01-22T15:33:22.748100Z","iopub.status.idle":"2025-01-22T15:33:31.262947Z","shell.execute_reply.started":"2025-01-22T15:33:22.748025Z","shell.execute_reply":"2025-01-22T15:33:31.262042Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\n# Load metadata\nmetadata_path = '/kaggle/input/chexpert/train.csv'\ndf = pd.read_csv(metadata_path)\n\n# Display columns\nprint(df.columns)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T03:43:46.069822Z","iopub.execute_input":"2025-01-23T03:43:46.070230Z","iopub.status.idle":"2025-01-23T03:43:46.787578Z","shell.execute_reply.started":"2025-01-23T03:43:46.070200Z","shell.execute_reply":"2025-01-23T03:43:46.786642Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define label columns\nlabel_columns = ['Cardiomegaly', 'Edema', 'Consolidation', 'Pneumonia', 'No Finding']\n\n# Extract image paths and labels\ndf['Path'] = df['Path'].apply(lambda x: f\"/kaggle/input/chexpert/{x}\")  # Ensure correct path\nlabels = df[label_columns].fillna(0).astype(int)  # Replace NaNs and convert to integers\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T03:44:22.399016Z","iopub.execute_input":"2025-01-23T03:44:22.399320Z","iopub.status.idle":"2025-01-23T03:44:22.511895Z","shell.execute_reply.started":"2025-01-23T03:44:22.399296Z","shell.execute_reply":"2025-01-23T03:44:22.511082Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df[label_columns] = df[label_columns].replace(-1, 0)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T03:45:00.088552Z","iopub.execute_input":"2025-01-23T03:45:00.088950Z","iopub.status.idle":"2025-01-23T03:45:00.113251Z","shell.execute_reply.started":"2025-01-23T03:45:00.088917Z","shell.execute_reply":"2025-01-23T03:45:00.112281Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df[label_columns] = df[label_columns].replace(-1, 1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T03:46:24.922921Z","iopub.execute_input":"2025-01-23T03:46:24.923240Z","iopub.status.idle":"2025-01-23T03:46:24.948247Z","shell.execute_reply.started":"2025-01-23T03:46:24.923213Z","shell.execute_reply":"2025-01-23T03:46:24.947368Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df[label_columns]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T03:46:29.029620Z","iopub.execute_input":"2025-01-23T03:46:29.029966Z","iopub.status.idle":"2025-01-23T03:46:29.048237Z","shell.execute_reply.started":"2025-01-23T03:46:29.029937Z","shell.execute_reply":"2025-01-23T03:46:29.047511Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Combine image paths and labels\ndataset = pd.concat([df['Path'], labels], axis=1)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T03:47:17.040862Z","iopub.execute_input":"2025-01-23T03:47:17.041154Z","iopub.status.idle":"2025-01-23T03:47:17.058438Z","shell.execute_reply.started":"2025-01-23T03:47:17.041129Z","shell.execute_reply":"2025-01-23T03:47:17.057686Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T03:47:29.466278Z","iopub.execute_input":"2025-01-23T03:47:29.466644Z","iopub.status.idle":"2025-01-23T03:47:29.475170Z","shell.execute_reply.started":"2025-01-23T03:47:29.466616Z","shell.execute_reply":"2025-01-23T03:47:29.474363Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\n# Load metadata\nmetadata_path = '/kaggle/input/chexpert/train.csv'\ndf = pd.read_csv(metadata_path)\n\n# Ensure all label columns are numeric and replace invalid values\nlabel_columns = ['Cardiomegaly', 'Edema', 'Consolidation', 'Pneumonia', 'No Finding']\ndf[label_columns] = df[label_columns].apply(pd.to_numeric, errors='coerce').fillna(0).astype(float)\n\ndf['Path'] = df['Path'].str.replace(\n    'CheXpert-v1.0-small/', '', regex=False\n)  # Remove the incorrect prefix\n\n# Ensure paths are correct for Kaggle directory structure\ndf['Path'] = df['Path'].apply(lambda x: f\"/kaggle/input/chexpert/{x}\")\n\n# Combine paths and labels\ndataset = pd.concat([df['Path'], df[label_columns]], axis=1)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T04:02:48.172402Z","iopub.execute_input":"2025-01-23T04:02:48.172765Z","iopub.status.idle":"2025-01-23T04:02:48.965142Z","shell.execute_reply.started":"2025-01-23T04:02:48.172738Z","shell.execute_reply":"2025-01-23T04:02:48.964445Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Load metadata\nmetadata_path = '/kaggle/input/chexpert/valid.csv'\ndf = pd.read_csv(metadata_path)\n\n# Ensure all label columns are numeric and replace invalid values\nlabel_columns = ['Cardiomegaly', 'Edema', 'Consolidation', 'Pneumonia', 'No Finding']\ndf[label_columns] = df[label_columns].apply(pd.to_numeric, errors='coerce').fillna(0).astype(float)\n\ndf['Path'] = df['Path'].str.replace(\n    'CheXpert-v1.0-small/', '', regex=False\n)  # Remove the incorrect prefix\n\n# Ensure paths are correct for Kaggle directory structure\ndf['Path'] = df['Path'].apply(lambda x: f\"/kaggle/input/chexpert/{x}\")\n\n# Combine paths and labels\ndataset_valid = pd.concat([df['Path'], df[label_columns]], axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T04:11:00.446949Z","iopub.execute_input":"2025-01-23T04:11:00.447273Z","iopub.status.idle":"2025-01-23T04:11:00.459897Z","shell.execute_reply.started":"2025-01-23T04:11:00.447247Z","shell.execute_reply":"2025-01-23T04:11:00.459212Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(dataset.head())  # Preview the DataFrame","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T04:03:22.040734Z","iopub.execute_input":"2025-01-23T04:03:22.041009Z","iopub.status.idle":"2025-01-23T04:03:22.048751Z","shell.execute_reply.started":"2025-01-23T04:03:22.040987Z","shell.execute_reply":"2025-01-23T04:03:22.047826Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(dataset_valid.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T04:11:14.938234Z","iopub.execute_input":"2025-01-23T04:11:14.938593Z","iopub.status.idle":"2025-01-23T04:11:14.946258Z","shell.execute_reply.started":"2025-01-23T04:11:14.938567Z","shell.execute_reply":"2025-01-23T04:11:14.945489Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torch.utils.data import Dataset\nfrom PIL import Image\nimport torch\n\nclass CheXpertDataset(Dataset):\n    def __init__(self, dataframe, transform=None):\n        self.dataframe = dataframe\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.dataframe)\n\n    def __getitem__(self, idx):\n        row = self.dataframe.iloc[idx]\n        \n        # Load the image\n        image_path = row['Path']\n        image = Image.open(image_path).convert('RGB')\n        \n        # Convert labels to a float tensor\n        label = torch.tensor(row[1:].values.astype(float), dtype=torch.float32)\n        \n        # Apply transformations\n        if self.transform:\n            image = self.transform(image)\n        \n        return image, label\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T04:03:47.701203Z","iopub.execute_input":"2025-01-23T04:03:47.701554Z","iopub.status.idle":"2025-01-23T04:03:47.707270Z","shell.execute_reply.started":"2025-01-23T04:03:47.701527Z","shell.execute_reply":"2025-01-23T04:03:47.706535Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torchvision import transforms\nfrom torch.utils.data import DataLoader\nfrom torchvision.datasets import ImageFolder\n\n# Define transformations\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),  # Resize for ViT\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(10),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize\n])\n\ntransform_valid = transforms.Compose([\n    transforms.Resize((224, 224)),  # Resize for ViT\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize\n])\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T04:11:53.794356Z","iopub.execute_input":"2025-01-23T04:11:53.794659Z","iopub.status.idle":"2025-01-23T04:11:53.800061Z","shell.execute_reply.started":"2025-01-23T04:11:53.794636Z","shell.execute_reply":"2025-01-23T04:11:53.799200Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dataset = CheXpertDataset(dataframe=dataset, transform=transform)\nvalid_dataset = CheXpertDataset(dataframe=dataset_valid, transform=transform)\n\n# Create DataLoader instances\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\nvalid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False, num_workers=2)\n\n# Example: Iterate over the DataLoader\nfor images, labels in train_loader:\n    print(\"Image batch shape:\", images.shape)\n    print(\"Label batch shape:\", labels.shape)\n    break\n\nfor images, labels in valid_loader:\n    print(\"Image batch shape:\", images.shape)\n    print(\"Label batch shape:\", labels.shape)\n    break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T04:13:03.779185Z","iopub.execute_input":"2025-01-23T04:13:03.779575Z","iopub.status.idle":"2025-01-23T04:13:05.456175Z","shell.execute_reply.started":"2025-01-23T04:13:03.779546Z","shell.execute_reply":"2025-01-23T04:13:05.455200Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import ViTForImageClassification, ViTImageProcessor\nfrom torch.optim import AdamW\nimport torch.nn as nn\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\nimport torch\n\n# Load pretrained ViT\nmodel_name = \"google/vit-base-patch16-224\"\nmodel = ViTForImageClassification.from_pretrained(model_name, num_labels=5, ignore_mismatched_sizes=True)  # Adjust num_labels\n\n# Processor for ViT\nprocessor = ViTImageProcessor.from_pretrained(model_name)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n# Define optimizer and scheduler\noptimizer = AdamW(model.parameters(), lr=3e-5)\nscheduler = CosineAnnealingLR(optimizer, T_max=10)\n\n# Loss function\ncriterion = nn.BCEWithLogitsLoss()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T04:09:37.924065Z","iopub.execute_input":"2025-01-23T04:09:37.924413Z","iopub.status.idle":"2025-01-23T04:09:39.242537Z","shell.execute_reply.started":"2025-01-23T04:09:37.924382Z","shell.execute_reply":"2025-01-23T04:09:39.241827Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_model(model, train_loader, valid_loader, optimizer, scheduler, criterion, device, epochs=5):\n    scaler = torch.amp.GradScaler()\n    model.to(device)\n\n    for epoch in range(epochs):\n        print(f\"Epoch {epoch + 1}/{epochs}\")\n\n        # Training Phase\n        model.train()\n        train_loss = 0.0\n\n        for images, labels in train_loader:\n            images, labels = images.to(device), labels.to(device)\n\n            with torch.amp.autocast(device_type=\"cuda\"):\n                outputs = model(images)\n                logits = outputs.logits if hasattr(outputs, \"logits\") else outputs  # Extract logits\n                loss = criterion(logits, labels)\n\n            scaler.scale(loss).backward()\n            scaler.step(optimizer)\n            scaler.update()\n            optimizer.zero_grad()\n\n            train_loss += loss.item()\n\n        # Print average training loss\n        train_loss /= len(train_loader)\n        print(f\"Training Loss: {train_loss:.4f}\")\n\n        # Validation Phase\n        model.eval()\n        valid_loss = 0.0\n        correct_predictions = 0\n        total_predictions = 0\n\n        with torch.no_grad():\n            for images, labels in valid_loader:\n                images, labels = images.to(device), labels.to(device)\n\n                with torch.amp.autocast(device_type=\"cuda\"):\n                    outputs = model(images)\n                    logits = outputs.logits if hasattr(outputs, \"logits\") else outputs  # Extract logits\n                    loss = criterion(logits, labels)\n\n                valid_loss += loss.item()\n\n                # Calculate accuracy (for multi-label, use a threshold)\n                predictions = (torch.sigmoid(logits) > 0.5).float()  # Apply sigmoid for binary classification\n                correct_predictions += (predictions == labels).sum().item()\n                total_predictions += labels.numel()\n\n        # Print average validation loss and accuracy\n        valid_loss /= len(valid_loader)\n        accuracy = correct_predictions / total_predictions * 100\n        print(f\"Validation Loss: {valid_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n\n        # Step the scheduler (optional, if using learning rate scheduling)\n        if scheduler is not None:\n            scheduler.step(valid_loss)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T04:18:12.452084Z","iopub.execute_input":"2025-01-23T04:18:12.452517Z","iopub.status.idle":"2025-01-23T04:18:12.461432Z","shell.execute_reply.started":"2025-01-23T04:18:12.452484Z","shell.execute_reply":"2025-01-23T04:18:12.460448Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_model(\n    model=model,\n    train_loader=train_loader,\n    valid_loader=valid_loader,\n    optimizer=optimizer,\n    scheduler=None,  # Pass `None` if not using a scheduler\n    criterion=criterion,\n    device=device,\n    epochs=10\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T04:18:47.262845Z","iopub.execute_input":"2025-01-23T04:18:47.263218Z","iopub.status.idle":"2025-01-23T04:19:25.518774Z","shell.execute_reply.started":"2025-01-23T04:18:47.263192Z","shell.execute_reply":"2025-01-23T04:19:25.517606Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.save_pretrained(\"/kaggle/working/vit-chest-xray\")\nprocessor.save_pretrained(\"/kaggle/working/vit-chest-xray\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T04:19:41.434714Z","iopub.execute_input":"2025-01-23T04:19:41.435058Z","iopub.status.idle":"2025-01-23T04:19:42.255550Z","shell.execute_reply.started":"2025-01-23T04:19:41.435028Z","shell.execute_reply":"2025-01-23T04:19:42.254455Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install huggingface-hub\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T04:19:46.631937Z","iopub.execute_input":"2025-01-23T04:19:46.632242Z","iopub.status.idle":"2025-01-23T04:19:50.594860Z","shell.execute_reply.started":"2025-01-23T04:19:46.632218Z","shell.execute_reply":"2025-01-23T04:19:50.593908Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from huggingface_hub import notebook_login\nnotebook_login()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T04:25:51.263965Z","iopub.execute_input":"2025-01-23T04:25:51.264387Z","iopub.status.idle":"2025-01-23T04:25:51.282592Z","shell.execute_reply.started":"2025-01-23T04:25:51.264350Z","shell.execute_reply":"2025-01-23T04:25:51.281702Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from huggingface_hub import HfApi, HfFolder\n\n# Define repository name (your Hugging Face username/repository)\nrepo_name = \"vit-chest-xray\"\n\n# Upload to Hugging Face\nmodel.push_to_hub(repo_name)\nprocessor.push_to_hub(repo_name)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T04:25:59.539869Z","iopub.execute_input":"2025-01-23T04:25:59.540175Z","iopub.status.idle":"2025-01-23T04:26:12.573872Z","shell.execute_reply.started":"2025-01-23T04:25:59.540152Z","shell.execute_reply":"2025-01-23T04:26:12.573120Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install datasets\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T04:26:18.359704Z","iopub.execute_input":"2025-01-23T04:26:18.360026Z","iopub.status.idle":"2025-01-23T04:26:21.705096Z","shell.execute_reply.started":"2025-01-23T04:26:18.360001Z","shell.execute_reply":"2025-01-23T04:26:21.704145Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from huggingface_hub import notebook_login\nnotebook_login()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T04:50:11.107988Z","iopub.execute_input":"2025-01-23T04:50:11.108282Z","iopub.status.idle":"2025-01-23T04:50:11.125325Z","shell.execute_reply.started":"2025-01-23T04:50:11.108253Z","shell.execute_reply":"2025-01-23T04:50:11.124315Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
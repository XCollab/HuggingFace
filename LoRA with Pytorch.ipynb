{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\">\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LoRA with PyTorch\n",
    "\n",
    "Estimated time needed: **60** minutes\n",
    "\n",
    "As an AI engineer, you are tasked with fine-tuning a model for sentiment analysis on the IMDB dataset, starting with a model that is pretrained on the AG News dataset. By leveraging Low-Rank Adaptation (LoRA), the model is initially trained on AG News, benefiting from its extensive labeled data and broad categorization capabilities. This robust foundation enhances the model’s language understanding.\n",
    "\n",
    "Subsequently, LoRA is used to fine-tune the model on the IMDB dataset, adapting its knowledge to the nuances of movie reviews for sentiment analysis. This two-phase process — starting with AG News and refining with IMDB data — ensures that the model is both well-rounded and specialized, achieving superior performance in sentiment analysis tasks.\n",
    "\n",
    "**Note: If you are already familiar with training a model on the IMDB dataset, you can run the cells and then jump to the Low-Rank Adaptation (LoRA) section**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "![Documents Overload](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-GPXX0Y15EN/docs.png)\n",
    "\n",
    "```Efficiency in parameter updates:``` LoRA introduces only a small fraction of additional parameters compared to the total number of parameters in a large model. This makes the training process faster and less resource-intensive because fewer parameters need to be updated during backpropagation.\n",
    "\n",
    "```Preservation of pretrained knowledge:``` By keeping the majority of the model's weights fixed and only adjusting them through low-rank matrices, LoRA helps preserve the rich representations that the model learned during pretraining. This is particularly beneficial for tasks that do not require drastic deviations from the behavior learned during pretraining.\n",
    "\n",
    "```Customization to specific tasks:``` Despite the minimal updates, the changes introduced by LoRA are significant enough to adapt the model to specific tasks. This lets you fine-tune large models on specialized tasks without the need for extensive retraining.\n",
    "\n",
    "```Reduction in overfitting:``` Because only a limited number of parameters are adapted, the risk of overfitting is lower compared to full model fine-tuning, especially when adapting to smaller datasets.\n",
    "\n",
    "```Scalability:``` LoRA scales well with model size. As models become larger, the relative increase in the number of parameters introduced by LoRA becomes even smaller, making it a particularly attractive option for adapting very large models.\n",
    "\n",
    "```Compatibility and simplicity:``` The method can be easily applied to different types of neural networks, especially those based on the transformer architecture. It doesn't require major changes to the existing architecture, which simplifies integration into existing pipelines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Table of Contents__\n",
    "\n",
    "<ol>\n",
    "    <li><a href=\"#Objectives\">Objectives</a></li>\n",
    "    <li>\n",
    "        <a href=\"#Setup\">Setup</a>\n",
    "        <ol>\n",
    "            <li><a href=\"#Install-required-libraries\">Install required libraries</a></li>\n",
    "            <li><a href=\"#Import-required-libraries\">Import required libraries</a></li>\n",
    "            <li><a href=\"#Defining-helper-functions\">Defining helper functions</a></li>\n",
    "        </ol>\n",
    "    </li>\n",
    "    <li>\n",
    "        <a href=\"#Data-pipeline\">Data pipeline</a>\n",
    "        <ol>\n",
    "            <li><a href=\"#Tokenizer\">Tokenizer</a></li>\n",
    "        </ol>\n",
    "    </li>\n",
    "    <li>\n",
    "        <a href=\"#IMDB-dataset\">IMDB dataset</a></li>\n",
    "        <ol>\n",
    "            <li><a href=\"#Dataset-composition\">Dataset composition</a></li>\n",
    "            <li><a href=\"#Applications\">Applications</a></li>\n",
    "            <li><a href=\"#Challenges\">Challenges</a></li>\n",
    "            <li><a href=\"#Train-and-validate\">Train and validate</a></li>\n",
    "            <li><a href=\"#Data-loader\">Data loader</a></li>\n",
    "            <li><a href=\"#Neural-network\">Neural network</a></li>\n",
    "        </ol>\n",
    "     </li>\n",
    "    <li>\n",
    "        <a href=\"#Train-the-model-on-the-full-dataset\">Train the model on the full dataset</a></li>\n",
    "        <ol>\n",
    "            <li><a href=\"#Train-the-model\">Train the model</a></li>\n",
    "        </ol>\n",
    "     </li>\n",
    "    <li>\n",
    "        <a href=\"#Low-Rank-Adaptation-(LoRA)\">Low-Rank Adaptation (LoRA)</a></li>\n",
    "        <ol>\n",
    "            <li><a href=\"#LoRA\">LoRA</a></li>\n",
    "            <li><a href=\"#Rank\">Rank</a></li>\n",
    "            <li><a href=\"#Understanding-LoRA-in-PyTorch\">Understanding LoRA in PyTorch</a></li>\n",
    "            <li><a href=\"#Applying-LoRA\">Applying LoRA</a></li>\n",
    "            <li><a href=\"#Loading-the-model\">Loading the model</a></li>\n",
    "        </ol>\n",
    "     </li>\n",
    "    <li>\n",
    "        <a href=\"#Exercise:-Apply-LoRA-to-a-different-network\">Exercise: Apply LoRA to a different network</a>\n",
    "    </li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "After completing this lab you are able to:\n",
    "\n",
    "- Construct and train a neural network from the ground up\n",
    "- Fine-tune a neural network in the conventional manner by unfreezing specific layers\n",
    "- Use LoRA to fine-tune a neural network\n",
    "- Comprehend the functions of LoRA and the reasons behind its effectiveness\n",
    "- Save and load models that employ LoRA efficiently\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install required libraries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following required libraries are __not__ preinstalled in the Skills Network Labs environment. __You must run the following cell__ to install them. Note that it can take between __5 and 10 minutes__ to install the required libraries:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.24.1\n",
      "  Downloading numpy-1.24.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "Downloading numpy-1.24.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m97.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "Successfully installed numpy-1.24.1\n",
      "Collecting portalocker==2.8.2\n",
      "  Downloading portalocker-2.8.2-py3-none-any.whl.metadata (8.5 kB)\n",
      "Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
      "Installing collected packages: portalocker\n",
      "Successfully installed portalocker-2.8.2\n",
      "Collecting torch==2.0.1\n",
      "  Downloading torch-2.0.1-cp311-cp311-manylinux1_x86_64.whl.metadata (24 kB)\n",
      "Collecting filelock (from torch==2.0.1)\n",
      "  Downloading filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.11/site-packages (from torch==2.0.1) (4.12.2)\n",
      "Collecting sympy (from torch==2.0.1)\n",
      "  Downloading sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch==2.0.1)\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch==2.0.1) (3.1.3)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.1)\n",
      "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.1)\n",
      "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.1)\n",
      "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.1)\n",
      "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.1)\n",
      "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.1)\n",
      "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.1)\n",
      "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.1)\n",
      "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.1)\n",
      "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.1)\n",
      "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.1)\n",
      "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==2.0.0 (from torch==2.0.1)\n",
      "  Downloading triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (69.5.1)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.11/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (0.43.0)\n",
      "Collecting cmake (from triton==2.0.0->torch==2.0.1)\n",
      "  Downloading cmake-3.31.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
      "Collecting lit (from triton==2.0.0->torch==2.0.1)\n",
      "  Downloading lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch==2.0.1) (2.1.5)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch==2.0.1)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Downloading torch-2.0.1-cp311-cp311-manylinux1_x86_64.whl (619.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m780.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m392.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m547.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m78.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cmake-3.31.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.8/27.8 MB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading lit-18.1.8-py3-none-any.whl (96 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mpmath, lit, sympy, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, networkx, filelock, cmake, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch\n",
      "Successfully installed cmake-3.31.2 filelock-3.16.1 lit-18.1.8 mpmath-1.3.0 networkx-3.4.2 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 sympy-1.13.3 torch-2.0.1 triton-2.0.0\n",
      "Collecting torchtext==0.15.2\n",
      "  Downloading torchtext-0.15.2-cp311-cp311-manylinux1_x86_64.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from torchtext==0.15.2) (4.66.4)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from torchtext==0.15.2) (2.31.0)\n",
      "Requirement already satisfied: torch==2.0.1 in /opt/conda/lib/python3.11/site-packages (from torchtext==0.15.2) (2.0.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from torchtext==0.15.2) (1.24.1)\n",
      "Collecting torchdata==0.6.1 (from torchtext==0.15.2)\n",
      "  Downloading torchdata-0.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch==2.0.1->torchtext==0.15.2) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.11/site-packages (from torch==2.0.1->torchtext==0.15.2) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch==2.0.1->torchtext==0.15.2) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch==2.0.1->torchtext==0.15.2) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch==2.0.1->torchtext==0.15.2) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /opt/conda/lib/python3.11/site-packages (from torch==2.0.1->torchtext==0.15.2) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /opt/conda/lib/python3.11/site-packages (from torch==2.0.1->torchtext==0.15.2) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /opt/conda/lib/python3.11/site-packages (from torch==2.0.1->torchtext==0.15.2) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /opt/conda/lib/python3.11/site-packages (from torch==2.0.1->torchtext==0.15.2) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /opt/conda/lib/python3.11/site-packages (from torch==2.0.1->torchtext==0.15.2) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /opt/conda/lib/python3.11/site-packages (from torch==2.0.1->torchtext==0.15.2) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /opt/conda/lib/python3.11/site-packages (from torch==2.0.1->torchtext==0.15.2) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /opt/conda/lib/python3.11/site-packages (from torch==2.0.1->torchtext==0.15.2) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /opt/conda/lib/python3.11/site-packages (from torch==2.0.1->torchtext==0.15.2) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /opt/conda/lib/python3.11/site-packages (from torch==2.0.1->torchtext==0.15.2) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /opt/conda/lib/python3.11/site-packages (from torch==2.0.1->torchtext==0.15.2) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /opt/conda/lib/python3.11/site-packages (from torch==2.0.1->torchtext==0.15.2) (2.0.0)\n",
      "Requirement already satisfied: urllib3>=1.25 in /opt/conda/lib/python3.11/site-packages (from torchdata==0.6.1->torchtext==0.15.2) (2.2.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->torchtext==0.15.2) (69.5.1)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.11/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->torchtext==0.15.2) (0.43.0)\n",
      "Requirement already satisfied: cmake in /opt/conda/lib/python3.11/site-packages (from triton==2.0.0->torch==2.0.1->torchtext==0.15.2) (3.31.2)\n",
      "Requirement already satisfied: lit in /opt/conda/lib/python3.11/site-packages (from triton==2.0.0->torch==2.0.1->torchtext==0.15.2) (18.1.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->torchtext==0.15.2) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->torchtext==0.15.2) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->torchtext==0.15.2) (2024.12.14)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch==2.0.1->torchtext==0.15.2) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy->torch==2.0.1->torchtext==0.15.2) (1.3.0)\n",
      "Downloading torchtext-0.15.2-cp311-cp311-manylinux1_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torchdata-0.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torchdata, torchtext\n",
      "Successfully installed torchdata-0.6.1 torchtext-0.15.2\n",
      "Requirement already satisfied: torchdata==0.6.1 in /opt/conda/lib/python3.11/site-packages (0.6.1)\n",
      "Requirement already satisfied: urllib3>=1.25 in /opt/conda/lib/python3.11/site-packages (from torchdata==0.6.1) (2.2.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from torchdata==0.6.1) (2.31.0)\n",
      "Requirement already satisfied: torch==2.0.1 in /opt/conda/lib/python3.11/site-packages (from torchdata==0.6.1) (2.0.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch==2.0.1->torchdata==0.6.1) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.11/site-packages (from torch==2.0.1->torchdata==0.6.1) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch==2.0.1->torchdata==0.6.1) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch==2.0.1->torchdata==0.6.1) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch==2.0.1->torchdata==0.6.1) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /opt/conda/lib/python3.11/site-packages (from torch==2.0.1->torchdata==0.6.1) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /opt/conda/lib/python3.11/site-packages (from torch==2.0.1->torchdata==0.6.1) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /opt/conda/lib/python3.11/site-packages (from torch==2.0.1->torchdata==0.6.1) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /opt/conda/lib/python3.11/site-packages (from torch==2.0.1->torchdata==0.6.1) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /opt/conda/lib/python3.11/site-packages (from torch==2.0.1->torchdata==0.6.1) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /opt/conda/lib/python3.11/site-packages (from torch==2.0.1->torchdata==0.6.1) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /opt/conda/lib/python3.11/site-packages (from torch==2.0.1->torchdata==0.6.1) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /opt/conda/lib/python3.11/site-packages (from torch==2.0.1->torchdata==0.6.1) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /opt/conda/lib/python3.11/site-packages (from torch==2.0.1->torchdata==0.6.1) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /opt/conda/lib/python3.11/site-packages (from torch==2.0.1->torchdata==0.6.1) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /opt/conda/lib/python3.11/site-packages (from torch==2.0.1->torchdata==0.6.1) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /opt/conda/lib/python3.11/site-packages (from torch==2.0.1->torchdata==0.6.1) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->torchdata==0.6.1) (69.5.1)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.11/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->torchdata==0.6.1) (0.43.0)\n",
      "Requirement already satisfied: cmake in /opt/conda/lib/python3.11/site-packages (from triton==2.0.0->torch==2.0.1->torchdata==0.6.1) (3.31.2)\n",
      "Requirement already satisfied: lit in /opt/conda/lib/python3.11/site-packages (from triton==2.0.0->torch==2.0.1->torchdata==0.6.1) (18.1.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->torchdata==0.6.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->torchdata==0.6.1) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->torchdata==0.6.1) (2024.12.14)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch==2.0.1->torchdata==0.6.1) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy->torch==2.0.1->torchdata==0.6.1) (1.3.0)\n",
      "Collecting plotly==5.22.0\n",
      "  Downloading plotly-5.22.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.11/site-packages (from plotly==5.22.0) (9.0.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from plotly==5.22.0) (24.0)\n",
      "Downloading plotly-5.22.0-py3-none-any.whl (16.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m94.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: plotly\n",
      "  Attempting uninstall: plotly\n",
      "    Found existing installation: plotly 5.24.1\n",
      "    Uninstalling plotly-5.24.1:\n",
      "\u001b[31mERROR: Could not install packages due to an OSError: [Errno 13] Permission denied: '/opt/conda/etc/jupyter/nbconfig/notebook.d/jupyterlab-plotly.json'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\u001b[0m\u001b[31m\n",
      "\u001b[0mCollecting pandas==2.2.2\n",
      "  Downloading pandas-2.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /opt/conda/lib/python3.11/site-packages (from pandas==2.2.2) (1.24.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas==2.2.2) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas==2.2.2) (2024.1)\n",
      "Collecting tzdata>=2022.7 (from pandas==2.2.2)\n",
      "  Downloading tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas==2.2.2) (1.16.0)\n",
      "Downloading pandas-2.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m106.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.6/346.6 kB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tzdata, pandas\n",
      "Successfully installed pandas-2.2.2 tzdata-2024.2\n",
      "Collecting matplotlib==3.9.0\n",
      "  Downloading matplotlib-3.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib==3.9.0)\n",
      "  Downloading contourpy-1.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib==3.9.0)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib==3.9.0)\n",
      "  Downloading fonttools-4.55.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (165 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.1/165.1 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib==3.9.0)\n",
      "  Downloading kiwisolver-1.4.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/conda/lib/python3.11/site-packages (from matplotlib==3.9.0) (1.24.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib==3.9.0) (24.0)\n",
      "Collecting pillow>=8 (from matplotlib==3.9.0)\n",
      "  Downloading pillow-11.1.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib==3.9.0)\n",
      "  Downloading pyparsing-3.2.1-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.11/site-packages (from matplotlib==3.9.0) (2.9.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib==3.9.0) (1.16.0)\n",
      "Downloading matplotlib-3.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m106.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (326 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m326.2/326.2 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.55.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m89.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m75.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pillow-11.1.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m95.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.2.1-py3-none-any.whl (107 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.7/107.7 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.1 cycler-0.12.1 fonttools-4.55.3 kiwisolver-1.4.8 matplotlib-3.9.0 pillow-11.1.0 pyparsing-3.2.1\n",
      "Collecting scikit-learn==1.5.0\n",
      "  Downloading scikit_learn-1.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /opt/conda/lib/python3.11/site-packages (from scikit-learn==1.5.0) (1.24.1)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn==1.5.0)\n",
      "  Downloading scipy-1.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting joblib>=1.2.0 (from scikit-learn==1.5.0)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn==1.5.0)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m94.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (40.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.6/40.6 MB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.5.0 scipy-1.15.0 threadpoolctl-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy==1.24.1\n",
    "!pip install -U portalocker==2.8.2\n",
    "!pip install torch==2.0.1\n",
    "!pip install torchtext==0.15.2\n",
    "!pip install torchdata==0.6.1\n",
    "!pip install -U plotly==5.22.0\n",
    "!pip install pandas==2.2.2\n",
    "!pip install matplotlib==3.9.0\n",
    "!pip install scikit-learn==1.5.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import required libraries\n",
    "\n",
    "The following imports the required libraries:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import accumulate\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchtext#; torchtext.disable_torchtext_deprecation_warning()\n",
    "from torchtext.vocab import build_vocab_from_iterator, GloVe, Vectors\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from torchtext.datasets import AG_NEWS\n",
    "from IPython.display import Markdown as md\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "from torch.utils.data.dataset import random_split,Dataset\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "from sklearn.manifold import TSNE\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "import pickle\n",
    "\n",
    "from urllib.request import urlopen\n",
    "import io\n",
    "\n",
    "import tarfile\n",
    "import tempfile\n",
    "\n",
    "# You can also use this section to suppress warnings generated by your code:\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining helper functions\n",
    "\n",
    "The following are some helper functions to help with plotting, saving, and loading files. These functions are not the main focus of this lab, you do not have to dwell on these too long. However, do run the cells in this section to define these helper functions:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(COST,ACC):\n",
    "    fig, ax1 = plt.subplots()\n",
    "    color = 'tab:red'\n",
    "    ax1.plot(COST, color=color)\n",
    "    ax1.set_xlabel('epoch', color=color)\n",
    "    ax1.set_ylabel('total loss', color=color)\n",
    "    ax1.tick_params(axis='y', color=color)\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    color = 'tab:blue'\n",
    "    ax2.set_ylabel('accuracy', color=color)  # You already handled the x-label with ax1\n",
    "    ax2.plot(ACC, color=color)\n",
    "    ax2.tick_params(axis='y', color=color)\n",
    "    fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_list_to_file(lst, filename):\n",
    "    \"\"\"\n",
    "    Save a list to a file using pickle serialization.\n",
    "\n",
    "    Parameters:\n",
    "        lst (list): The list to be saved.\n",
    "        filename (str): The name of the file to save the list to.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    with open(filename, 'wb') as file:\n",
    "        pickle.dump(lst, file)\n",
    "\n",
    "def load_list_from_file(filename):\n",
    "    \"\"\"\n",
    "    Load a list from a file using pickle deserialization.\n",
    "\n",
    "    Parameters:\n",
    "        filename (str): The name of the file to load the list from.\n",
    "\n",
    "    Returns:\n",
    "        list: The loaded list.\n",
    "    \"\"\"\n",
    "    with open(filename, 'rb') as file:\n",
    "        loaded_list = pickle.load(file)\n",
    "    return loaded_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tokenizer takes as input a document and breaks it up into individual tokens. Now, you might wonder, what's a token?\n",
    "This example might help you understand it better.\n",
    "\n",
    "Imagine a token as a puzzle piece of a jigsaw puzzle. Each word, number, or small part of a word is a token. When you tokenize a document, you break it into these puzzle pieces so that a computer can understand and work with the text more easily, just like how you solve a puzzle by arranging its pieces.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, import the **```get_tokenizer```** function from **```torchtext.data.utils```**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll create the tokenizer. We'll set it to the \"basic_english\" tokenizer that is provided by `torchtext`. The \"basic_english\" tokenizer is designed to handle basic English text and splits the text into individual tokens based on spaces and punctuation marks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer(\"basic_english\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset is going to be an iterable. Therefore, We'll use a generator function **```yield_tokens```** to apply **```tokenizer```**. The purpose of the generator function **```yield_tokens```** is to yield tokenized texts one at a time. Instead of processing the entire dataset and returning all of the tokenized texts in one go, the generator function processes and yields each tokenized text individually as it is requested. The tokenization process is performed lazily, which means the next tokenized text is generated only when needed, saving memory and computational resources.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_tokens(data_iter):\n",
    "    for  _,text in data_iter:\n",
    "        yield tokenizer(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following loads a pretrained word embedding model called GloVe into a variable called `glove_embedding`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that GloVe embeddings are typically downloaded using:\n",
    "#glove_embedding = GloVe(name=\"6B\", dim=100)\n",
    "# However, the GloVe server is frequently down. The code below offers a workaround\n",
    "\n",
    "\n",
    "class GloVe_override(Vectors):\n",
    "    url = {\n",
    "        \"6B\": \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/tQdezXocAJMBMPfUJx_iUg/glove-6B.zip\",\n",
    "    }\n",
    "\n",
    "    def __init__(self, name=\"6B\", dim=100, **kwargs) -> None:\n",
    "        url = self.url[name]\n",
    "        name = \"glove.{}.{}d.txt\".format(name, str(dim))\n",
    "        #name = \"glove.{}/glove.{}.{}d.txt\".format(name, name, str(dim))\n",
    "        super(GloVe_override, self).__init__(name, url=url, **kwargs)\n",
    "\n",
    "class GloVe_override2(Vectors):\n",
    "    url = {\n",
    "        \"6B\": \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/tQdezXocAJMBMPfUJx_iUg/glove-6B.zip\",\n",
    "    }\n",
    "\n",
    "    def __init__(self, name=\"6B\", dim=100, **kwargs) -> None:\n",
    "        url = self.url[name]\n",
    "        #name = \"glove.{}.{}d.txt\".format(name, str(dim))\n",
    "        name = \"glove.{}/glove.{}.{}d.txt\".format(name, name, str(dim))\n",
    "        super(GloVe_override2, self).__init__(name, url=url, **kwargs)\n",
    "\n",
    "try:\n",
    "    glove_embedding = GloVe_override(name=\"6B\", dim=100)\n",
    "except:\n",
    "    try:\n",
    "        glove_embedding = GloVe_override2(name=\"6B\", dim=100)\n",
    "    except:\n",
    "        glove_embedding = GloVe(name=\"6B\", dim=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following builds a vocabulary object from a pretrained GloVe word embedding model and sets the default index to the <unk> token:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torchtext.vocab import vocab\n",
    "vocab = vocab(glove_embedding .stoi, 0,specials=('<unk>', '<pad>'))\n",
    "vocab.set_default_index(vocab[\"<unk>\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following prepares the text processing pipeline with the tokenizer and vocabulary. The text pipeline will be used to process the raw data strings from the dataset iterators.\n",
    "\n",
    "The function **```text_pipeline```** first tokenizes the input text, following which **```vocab```** is applied to get the token indices.\n",
    "\n",
    "The function **```label_pipeline```** simply converts labels into their integer values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_pipeline(x):\n",
    "  return vocab(tokenizer(x))\n",
    "\n",
    "def label_pipeline(x):\n",
    "   return int(x) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMDB dataset \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following loads the IMDB dataset into a temporary folder. This might take some time, so please be patient.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlopened = urlopen('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/35t-FeC-2uN1ozOwPs7wFg.gz')\n",
    "tar = tarfile.open(fileobj=io.BytesIO(urlopened.read()))\n",
    "tempdir = tempfile.TemporaryDirectory()\n",
    "tar.extractall(tempdir.name)\n",
    "tar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **IMDB dataset** contains movie reviews from the Internet Movie Database (IMDB) and is commonly used for binary sentiment classification tasks. It's a popular dataset for training and testing models in natural language processing (NLP), particularly in the context of sentiment analysis.\n",
    "\n",
    "### Dataset composition\n",
    "\n",
    "- **Reviews**: The dataset consists of 50,000 movie reviews, divided evenly into 25,000 training and 25,000 testing samples.\n",
    "- **Sentiment labels**: Each review is labeled as either positive or negative, indicating the sentiment expressed in the review. The dataset is balanced, with an equal number of positive and negative reviews in both the training and testing sets.\n",
    "- **Text content**: Reviews are presented as plain text and have been preprocessed to some extent. For example, HTML tags are removed, but the text retains its original punctuation and capitalization.\n",
    "- **Usage**: The dataset is commonly used to train models for binary sentiment classification, where the goal is to predict whether a given review is positive or negative based on its text content.\n",
    "\n",
    "### Applications\n",
    "\n",
    "- **Sentiment analysis**: The primary application of the IMDB dataset is in sentiment analysis, where it serves as a benchmark for various text classification algorithms.\n",
    "- **Natural language processing (NLP)**: The dataset is widely used in NLP research and applications, providing a basis for testing the effectiveness of different models and approaches in understanding human language.\n",
    "\n",
    "### Challenges\n",
    "\n",
    "The dataset is small, so it's hard to train a model from scratch.\n",
    "\n",
    "The following class is defined to traverse the IMDB dataset. The need to define this class arises from the fact that the IMDB dataset is split across a large number of files:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMDBDataset(Dataset):\n",
    "    def __init__(self, root_dir, train=True):\n",
    "        \"\"\"\n",
    "        root_dir: The base directory of the IMDB dataset.\n",
    "        train: A boolean flag indicating whether to use training or test data.\n",
    "        \"\"\"\n",
    "        self.root_dir = os.path.join(root_dir, \"train\" if train else \"test\")\n",
    "        self.neg_files = [os.path.join(self.root_dir, \"neg\", f) for f in os.listdir(os.path.join(self.root_dir, \"neg\")) if f.endswith('.txt')]\n",
    "        self.pos_files = [os.path.join(self.root_dir, \"pos\", f) for f in os.listdir(os.path.join(self.root_dir, \"pos\")) if f.endswith('.txt')]\n",
    "        self.files = self.neg_files + self.pos_files\n",
    "        self.labels = [0] * len(self.neg_files) + [1] * len(self.pos_files)\n",
    "        self.pos_inx=len(self.pos_files)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.files[idx]\n",
    "        label = self.labels[idx]\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "            \n",
    "        return label, content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following uses the `IMDBDataset` class defined above to create iterators for the train and test datasets:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = tempdir.name + '/' + 'imdb_dataset'\n",
    "train_iter = IMDBDataset(root_dir=root_dir, train=True)  # For training data\n",
    "test_iter = IMDBDataset(root_dir=root_dir, train=False)  # For test dataart=train_iter.pos_inx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following prints 20 samples from the training set:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, \"It isn't always easy to explain what a movie is like, but this time I think I've found it. It reminded me of two movies: Trainspotting (small time criminals scoring some drugs and doing some stupid things in Schotland) and The Blair Witch Project (because of the style of filming).<br /><br />It's about the loyalty between two friends, one of them is coming out of jail, the other one hasn't been caught yet. With a stolen vehicle they drive through the Scottish countryside but than run out of petrol. As they try to find some fuel, they find a farm in the middle of nowhere. The farmer thinks they want to rob him and points a gun at one of them. Than it all goes wrong. One of the friends accidentally shoots the farmer's daughter and they have to run. What follows is a man hunt through the fields and woods of Schotland. The two friends literally have to run for their lives.<br /><br />Apparently this movie was shot in only 12 days time. OK, that's not exactly unbelievable because the biggest part of it is always in the same place: the Scottish countryside, but I still find that quite amazing. Especially because this isn't actually a bad movie. It's perhaps not the greatest movie ever, but they still can be proud of what they achieved. I had a nice time watching it and overall I enjoyed the movie. I give it a 7/10.\")\n",
      "(1, 'Pixar has had massive success over the years with the full-length CGI animated movies they have made. \"A Bug\\'s Life\" was the second of a whole bunch of features they have made so far, preceded by the company\\'s feature-length debut, the groundbreaking \"Toy Story\", which was the first ever feature-length CGI movie. I remember when this follow-up was heavily advertised around the time of its release in the late 1990\\'s, but I never actually saw it until November 2006. I watched it twice that month, and over three years later, I have seen it a third time. It has never impressed me as much as probably any other Pixar film I\\'ve ever seen, but after three viewings, I still think it\\'s better than some of the films I\\'ve seen from DreamWorks Animation.<br /><br />Ant Island is the home of a colony of ants. These ants are forced to gather food for a gang of grasshoppers who come and take it every year. One member of this colony is Flik, an inventor with a bad reputation for causing trouble with his inventions, even though he doesn\\'t mean to. One year, when the colony has just finished preparing the annual offering, Flik accidentally knocks it into a stream just before the grasshoppers arrive to get it! The grasshopper leader, Hopper, decides to give them a second chance to gather food and have it ready by the end of the season, but they will have to double their offering! Flik suggests to the colony\\'s royal council that he goes and finds \"warrior bugs\" to fight off the grasshoppers when they come back. Princess Atta, the future Queen, lets him go on this mission just so he won\\'t be around to cause trouble while the colony tries to gather food for another offering. The inventor finds a group of bugs which he thinks are warriors, but after he takes them back to Ant Island and introduces them, he learns that they are actually not warriors, but circus bugs!<br /><br />The main reason why this second Pixar feature has never absolutely astounded me might be the characters. To me, none of them have ever really stood out as much as they could have, and generally seem a bit bland. Fortunately, however, it\\'s not like \"Shark Tale\", a film with a very idiotic and unlikable lead character. \"A Bug\\'s Life\" does have a likable enough main character, one which viewers can root for. The story also seems somewhat bland at times, but for the most part, it\\'s good enough to keep the film at least moderately entertaining, and sometimes has some good suspense, especially later on. The humour, like certain other aspects of the film, isn\\'t as good as it could have been, but there are definitely funny moments, some of them involving Francis, a male ladybug who is sometimes mistaken for a female. You can always expect great animation from Pixar, and the animation in this particular effort of theirs is no exception. With all this movie has to offer, it may be slightly disappointing when it comes to Pixar standards, but it is reasonable family entertainment.')\n",
      "(1, \"I know I know it was a good ending but sincerely it was awesome. I love when a movie ends on a terrific dark nature but this time I was impressed with Darth Vader turning against the Emperor I really stayed astonished. The anguishing sequence in that film was when Luke is tortured and defeated by the Emperor/Darth Sidious. He is about to be destroyed when Darth Vader, Dark Lord of the Sith, eliminates his dark master. A nice sacrifice. The cinematography of this film is impressive. I was surprised with all the vessels of the Rebel Battle ships and all Imperial War Ships and Super Star Destroyers. I loved the new race they brought on screen the Mon Calomari, the ewoks, the sullesteian (Lando's co pilot) and many more... Most of my favorite scenes are in that film:1-When Vader destroys the Emperor and is fatally wounded. 2- When Luke sees the spirits of Obi-Wan and Yoda and then it shows up Anakin Skywalker (Sebastian Shaw)(the greatest scene in Star Wars) 3- When LEia slays Jabba strangling the Hutt crime lord.<br /><br />I personally like the script and the battle of Endor presenting a ground and space combat as well the best duel of Star Wars between Darth Vader V.s Luke Skywalker on the Death Star. Post-script: The scenes with Leia in the slave bikini are memorable. 9/10.\")\n",
      "(1, \"Don't listen to the many acerbic and derisory comments heaped upon this film.....simply put, as regards ninja movies, this my friends is about as good as it gets! <br /><br />Yes it's silly, yes the acting and script are admittedly absolutely atrocious, but by gum - it's so much bloody fun! In fact, as is often the case with B-Movies, the horrendous 'acting' (which in the case of the movie in question, is truly amongst the worst I have ever had the joy to behold!) and ridiculous 'plot' actually only serve to elevate the enjoyment level ten fold.<br /><br />Obviously the fight scenes are the main attraction in this though and for the most part I'm pleased to say, they're very well choreographed, especially the final showdown (during which we witness that ninja are not ostensibly constrained by the normal laws of gravity....) <br /><br />Trust me on this, if you are a fan of ninja movies and you have not yet seen Sakura Killers, then you are truly missing out on what is in my opinion, one of the true jewels in the crown of the genre.\")\n",
      "(1, \"I don't know why some guys from US, Georgia or even from Bulgaria have the courage to express feelings about something they don't understand at all. For those who did not watch this movie - watch it. Don't expect too much or don't put some frameworks just because this is Kosturica. Watch the movie without prejudice, try to understand the whole humor inside - people of Serbia DID actually getting married while Bil Clinton bomb their villages, gypsies in all Balkans are ALWAYS try to f*ck you up in any way they can, LOVE is always unexpected, pure and colorful, and Balkans are extremely creative. For those who claims this is a bad movie I can see only that the American's sh*t (like Meet Dave, Get Smart etc) are much much worse than a pure, frank Balkan humoristic love story movie as Promise me. The comment should be useful and on second place should represent the personal view of the writer. I think the movie is great and people watch it must give their respects to the director and story told inside. It is simple, but true. It is brutal, but gentle and makes you laugh to dead.\")\n",
      "(1, 'You got to go and dig those holes. Holes only leaves troble, which makes a movie so good. Disney has done it again.Shia LaBeouf should be nominated for Best Actor for his performance as Stanley Yelnats. He has alredy won the Daytime Emmy for Best Actor in a Comedy Series (Even Stevens). Holes is one of the best movies in 2003.')\n",
      "(1, 'What an entertaining movie. Astaire and Randolph Scott are in the Navy. Astaire has to woo back Ginger in San Francisco, while Scott must be persuaded that Harriet Hilliard is worthy of being his wife. Everything works out fine.<br /><br />It\\'s sometimes argued, and I can see why, that Scott\\'s romance with Hilliard is unnecessary and slows the plot down. Especially painful are Hilliard\\'s singing of sappy love songs. I could have done without her singing, right enough, but I found the romance rather touching. Hilliard enters the movie as a music teacher, wearing a pair of spectacles, no makeup, and the ugliest clothes known to man or beast. No wonder Scott avoids her until she grooms herself sexily under the tutelage of her sister Ginger and a slinky Lucille Ball. The problem is that AFTER her makeover she looks like the same irretrievably plain woman as before, only with a glossier outfit. It\\'s tough enough for a homely guy. But at least a man can become wealthy and powerful and popular, then he can collect women anyway, even if he looks like JoJo the Dog-Faced Boy. But what does a plain-looking woman do? The same avenues to romance aren\\'t open to her. Henry Kissinger had groupies. Did Margaret Thatcher? It must be terrible to be an ordinary woman in a culture as cruel as ours. As a kind of a footnote, I must mention that Randolph Scott was rumored to be bisexual by Hollywood gossips who needed some nonsense to chew on, and it\\'s kind of amusing that he has the following line in this film when he\\'s putting homely Hilliard off -- \"Women don\\'t interest me, sister.\" The movie probably gives more quality time to Ginger Rogers than any of her other films with Astaire. And she\\'s marvelous. She\\'s beautiful, sexy, a talented actress and dancer, and the script gives her good comic lines too. \"Let\\'s kiss and make up,\" suggests Astaire. \"Let\\'s just make up,\" she says, \"that will give you something to work on.\" It\\'s also the only film she made with Astaire that gives her a solo number during an audition. (Choreographed by Hermes Pan.) Her performance is accidentally sabotaged by Astaire who slips some Alka Seltzer or something into her water, and she hiccups through her number, burping being too indelicate for the time.<br /><br />As a dancer, I\\'d make a terrific circus elephant so my opinion must be taken as that of an amateur, but I think their dances together are the equal of any they put on film. Their first, during a dancing contest, \"Let Yourself Go,\" is the most wildly exuberant of any I can remember. And the only dramatic duet, \"Let\\'s Face the Music and Dance,\" must be among their finest. The last step as they exit is startling.<br /><br />I like the film for reasons with personal resonance. I remember seeing it for the first time in a theater in downtown San Diego, next to a shop called \"The Seven Seas\" that catered to sailors. I was in uniform at the time and was impressed with the treatment of the naval careers of Astaire and Scott. What I mean is, here we have this frothy musical comedy which owed absolutely nothing to historical reality, and yet, unlike most of their other teamings, pays its dues anyway. Jumping ship, Astaire calls out for a \"water taxi.\" I had just taken a water taxi ashore myself. The uniforms are correct to the period (unlike, say, those in \"On the Town\"). And they\\'re worn properly, hats down to two finger-widths above the eyebrow and not cocked back. And there are two incidents in which Astaire runs into a problem with naval authorities and they\\'re both handled with perfect seriousness and are thoroughly believable. An officer stops Astaire from leading a jazz band during inspection and reports to the captain, \"They were playing when the call was sounded, sir. I\\'m certain no breach of discipline was intended.\" It\\'s what an officer -- a good officer -- would say, and nobody laughs.<br /><br />The series was getting a little repetitious by the time \"Follow the Fleet\" was made so instead of putting Fred into high society and a tuxedo, they turned him into a gum-chewing swabbie instead. It was a good idea. And the dance numbers are up to the concept.')\n",
      "(1, \"THE NOTORIOUS BETTIE PAGE Written by Mary Harron & Guinevere Turner Directed by Mary Harron<br /><br />How do you define a person who has always been between two worlds, one of presumed sin and one of supposed redemption? Especially when that person eventually succumbed to a split personality disorder in her latter years as if to demonstrate her own point. If you're director Mary Harron, you don't shy away from showing the push/pull nature of THE NOTORIOUS BETTIE PAGE. You allow the character to drift back and forth between the healing forgiveness of the power of God and the church and the seductive illusion of control and dominance afforded to Page during her years as a pinup model. By doing so, audiences are offered a complex character that is propelled forward by a desire to leave her difficult past with a naive enjoyment in others' lust for her and a struggle to reconcile her image in the eyes of God. Come the right time, it will no longer matter how many eyes are on her because there is only one pair that counts.<br /><br />Shot mostly in black and white (with some unnecessary bursts of color), THE NOTORIOUS BETTIE PAGE is at times a light, humorous comedy, making the film an enjoyable experience and also one that pokes fun at how seriously people believe in the corruption of pornography. But the delicate hand of the director is more palpably felt during Page's times of despair. Harron is a sensitive, considerate director who does not throw Page's numerous and devastating blows of abuse in the face of her viewer. Instead, she allows the surprisingly effective Gretchen Moll, who plays the title role, the chance to hammer the pain of her character into the viewer with fear in her eyes, exhaustion is her cries and shame on her skin. Whereas most directors, perhaps most male directors, would find it essential to show the heroine in painful positions in order to draw a link between the kinds of atrocities that were put upon her and where her life took her, Harron has too much compassion for her character, her actress and her audience. From fragility, Page learns to trust people again and as more and more photographers fall in love with her image, the more she falls in love with their admiration and the control she has over the gaze. By the time her poses cross over into the realm of soft-core S&M, she has found a way to combine her need to be respected with the objectification she has been accustomed to her whole life.<br /><br />Mary Harron's Bettie Page is a woman who yearns for control over her life and destiny, yet ultimately is always being told where to stand, how to smile and what to wear. When she finally realizes that none of her choices have been her own, she chooses to embrace God and preach his word to those who will listen. The true sadness behind this most important decision is that she is still letting someone else guide her blindly; she just has more faith that this direction will be better for her soul.\")\n",
      "(1, 'As I reach the \"backside\" of 35 I find myself shaking my head more and more at the sex crazed, drug influenced teens of today. It was great to be reminded that it was just as crazy for me back in my day as it is for teens today. This film drives that point home to the core. If you are a late 70\\'s fan you\\'ll love the film. From KISS-posters to an Angel concert this movie rocks ! <br /><br />Watch for a young Laura Dern. Why they didn\\'t have more songs from the Runaways I\\'ll never know ? <br /><br />I did have a problem with Randy Quaid\\'s character deflowering a 16 year old girl. While he was away she and her friends have a party that destroys dude\\'s house. The cops come and everything but no mention of all the underage drinking and how these kids got their hands on this stuff.<br /><br />Foxes belongs right there with Over the Edge, Fast Times, Dazed & Confused, and Kids as one of the all time teen angst flicks.<br /><br />I say buy it and watch it with your kids and talk about it all.')\n",
      "(1, \"Barman directed Any Way the Wind Blows as he would sing a dEUS song. Anarchy rules over a logical and common strain of thoughts. The story behind this movie just goes any which way the wind blows. And that can truly be refreshing to watch, if you are prepared and willing that is. Viewers who state that there is nothing to keep the story-lines together are right. Who the hell is that Windman anyway? Still, I really enjoyed this movie. Antwerp is a beautiful, bustling, happening place and Any Way captures that feeling. It also captures the silliness, the racism, the bureaucracy, the addictions and the violence that survives undetected in a seemingly friendly city. The movie is entertaining, funny and a little shallow. Barman's screen debut will not make as heavy an impact as his music debut. In that light some might be disappointed. But then again, 'Worst Case Scenario' would be a subtle subtitle for Any Way the Wind Blows.\")\n",
      "(0, \"Your mind will not be satisfied by this no\\x97budget doomsday thriller; but, pray, who's will? A youngish couple spends the actual end of the world in the hidden laboratory of some aliens masquerading as Church people.<br /><br />Small _apocalyptically themed outing, END OF THE WORLD has the ingenuity and the lack of both brio and style of the purely '50s similar movies. And it's not only that, but EOTW plays like a hybrid\\x97not only doomsday but convent creeps as well. The villain of the movie is a well\\x97known character actor.<br /><br />This wholly shameless slapdash seems a piece of convent\\x97exploitation, that significantly '70s genre which looks today so amusingly outdated. Anyway, the convent's secret laboratory is some nasty piece of futuristic deco! Christopher Lee is the pride of End of the World; but the End of the World is not at all his pride!\")\n",
      "(0, 'I saw this movie the other night and I have to honestly say it\\'s one of the worst films I\\'ve ever seen. The acting is fair, but the plot is totally ridiculous. A killer is born because of all the \"energy used to make the movie\" and if the film is burned the killer will die? How unbelievable is that? The characters were underdeveloped to say the least...for example, all of a sudden the man mentions \"Aren\\'t you trying to complete the film because your mother couldn\\'t?\" So we\\'re supposed to go along with this? We had no idea it was her daughter until half way through the film. The movie really didn\\'t spotlight on anyone, we didn\\'t know anything about the main people who survived except Ringwald\\'s character was a whiney actress, the guy was on the set when the people died and Raffy wanted to be a director like her mother. Not truly diving in to know who they are. Seemed things were rushed to just get to the killings. The whole plot is entirely too weak for my taste and I was extremely disappointed. Anyone who enjoyed this piece of crap, obviously needs to learn a thing or two about film making. I can\\'t believe anyone would agree to star or even work on this picture. It\\'s not funny, it was not scary and was cliche through the entire film. I found myself predicting what would happen before each scene, which believe you me wasn\\'t hard at all to do. It\\'s a disgrace and I\\'m deeply sorry I wasted an hour and a half watching the mess. 1/10.')\n",
      "(0, \"'The Hills Eyes II', one of the most pointless and blatantly stupid sequels to come around in some time, is 90 minutes of incompetent film making at its finest. Or worst, however you choose to look at it. While 2006's 'Hills' remake was one of the year's best, and truly frightening, horror films, this sequel takes every spark out of what made that such an accomplishment. Part 2 never gets off the ground, and neither does its mind numbing dialogue. Worst of all, it's not that scary.<br /><br />2006's remake followed a family who find themselves in the middle of the New Mexico desert, deserted, and one by one being picked off by deranged and sadistic hill people. People who, as a result of the military testing the atomic bomb on their land years ago, have become who they are. Surviving off travelers who wander into the region. The sequel puts audiences in the same desert, now occupied by the military as they covertly investigate the hills and what might have happened to that poor family. When a group of military trainees are brought to the campsite, they find it deserted with no signs of life. A grim reality soon befalls them, as they come to the realization that they're not alone. And the bloody fate that was handed to many before them will soon become their destiny.<br /><br />It doesn't take a genius to realize that 'Hills' has no legitimate reason to exist. But because last year's remake was received well both at the box office and by critics, it came to no surprise that a sequel would be rushed into production while there's still money to be earned. There's no rhyme or reason to it this time around, just an unbelievable and ridiculous set-up to pave the way for thoughtless characters, unoriginal killings, a non-existent story, and slipping interest. Originally, director Alexander Aja made Craven's cult classic into a remake that was a unique and thoroughly disturbing experience. One that gruesomely crossed the line on more than one occasions. Its frank display of violence, sadistic torture, well-rounded characterization, and white-knuckled suspense were all effectively used to shock and repulse audiences. The second time around, it's rehashed hand-me-downs. There's no style, no grit. It tries to build up tension by dismembering bodies, when all it really does is make for a been there, done that kind film, where even the gore seems tame compared to more recent bloodbaths.<br /><br />It's a sad state of affairs when deformed mutants who capture women for breeding purposes fails to keep your attention. It's a bore, nothing more. 'Hills' has no bite. Despite a jump or two here and there, there's nothing very scary about this by-the-numbers horror flick. It feels like something you'd see on the Sci-Fi channel, only with some F-bombs, a blood splatter here and there, a rape, and a graphic birth scene that's more gross than shocking. It's cheap. And with 'Hills', you reap what you sew. With no effort given, you can't expect anything in return.<br /><br />Replacing Aja with Martin Weisz as director was the film's first big mistake, all he does is drain the film of any sort of emotional resonance. But even more shocking is the uncharacteristically bad script penned by Wes Craven and his son, Jonathan Craven. You ask, how bad could it possibly be? This is the kind of dialogue that makes any comparison look like Shakespeare. Craven has had his fair share of clunkers in the past, but I'd never expect something like this from him. It's so unintentionally funny, you have to wonder, is Craven playing a joke on this? Or did he dump this one on his son after the studio payed him off? The film's characters are one-dimensional talking heads with no emotions or common sense. The acting is just as bad. The only character who may win you over is 'Napoleon' Napoli, the scrawny kid who doesn't fit in with the others. Even the deranged and instinct-driven villains, who we might have found some favor with in the deepest of our thoughts a year ago, are met with indifferent. You don't hate them, you don't like them. You honestly couldn't care less. Just like this movie.<br /><br />Even if you were giddy with fear during 'The Hills Have Eyes', as I was, you'll have a tough time finding anything to enjoy in this piece of garbage. It's as generic as generic gets, and there's absolutely nothing here we haven't seen done many times already. I can't express this enough, avoid 'The Hills Have Eyes II' like the plague. It's frightless, unoriginal, frantic, and a bore. Stick to the remake or Craven's original vision. Because if you don't walk out after the first thirty minutes, don't say I didn't warn you.\")\n",
      "(0, \"This is one of those movies that appears on cable at like two in the afternoon to entertain bored housewives while they iron. The acting is second rate. Poor Mathew Modine seems to sleepwalk through the whole film. And god help Gina Gershon. Her accent is too over the top. It sounds nothing like an true English woman. It sounds forced and phony, much like her acting. She should stick to what she does best, lesbian showgirl con-artist who plays in a rock & roll band and has a drug problem. The other characters are no better. They are two dimensional. empty, vapid and silly. How are we to supposed to care about these people. At one point Christy Scott Cashman get's lost in Central Park. Really? It's not that hard to navigate Central Park. Just follow any path out. Not only did I not care about ANY of the characters,I downright hated them. The only reason I even stayed with this train-wreck of a film was Fisher Stevens. Even his brilliant humor couldn't save this dying Fish. Each scene is typical romantic comedy fare and nothing is left to surprise us. The script was awful as was the acting. If you catch this Fish throw it back!\")\n",
      "(0, 'Hands down the worst movie I have ever seen. I thought nothing would ever dethrone Last Action Hero, but this does easily. The movie is about 3 single guys who meet on Sundays to discuss their sexual escapades from the weekend. A fourth guy - who is married and - that used to be a part of the group shows up and talks about what he and his wife do. Nothing works in this movie. The jokes are not funny but they are repeated throughout the movie. The big kicker at the end of the movie is laughable. Avoid at all costs.')\n",
      "(0, \"This film was a critical and box-office fiasco back in 1957. It was based on a novel which was later turned into a play--which flopped on Broadway. The story is about some navy officers on leave in San Francisco during WWII. They have 4 day's leave which they spend at the Mark Hopkins hotel. The film meanders a lot and none of the characters seem very real. Cary Grant is generally brilliant in comedy and drama--but here he plays a sort of wheeler dealer and he doesn't really pull it off. Tony Curtis or James Garner would have been better choices. Audrey Hepburn was initially set to play opposite Grant, but had other commitments--so Suzy parker stepped in. She had never acted before, but was America's top photographic model at the time. I think that she did a good job, considering all the pressure that she was under. Grant's pairing with Jayne Mansfield in a few brief scenes--did not really work. The Studio was trying to give her some class by acting with Grant--but the character had no substance at all.\")\n",
      "(0, 'There is no way on earth you are going to care about any of these characters. A bunch of spoilt middle class overgrown kids take some drugs at a party and get off with each other and argue. I\\'ve just seen this on TV and I didn\\'t think it was a \\'film\\' as such, more a post-\\'This Life\\' indulgence that really has no resonance or proper drama to it. Stuff like this will get commissioned for time immemorial unfortunately, irrelevant middle class \"lifestyle\" crap that takes itself far too seriously. It\\'s got David Baddiel in it and that bird out of \"Cold Feet\", you know what to expect. There was a lot of this stuff about in 2000, it was a particularly British malaise...\"they\\'re educated and doing drugs? friends, but kinda dysfunctional and with incestuous relationships? sounds great!\". This kind of nonsense, and post-Guy Ritchie comedy- gangster stuff...dark days. If you have taste, this will annoy you to the point of violence.')\n",
      "(0, \"A scientist (John Carradine--sadly) finds out how to bring the dead back to life. However they come back with faces of marble. Eventually this all leads to disaster.<br /><br />Boring, totally predictable 1940s outing. This scared me silly when I was a kid but just bores me now. I had to struggle to stay awake! With one exception, the acting is horrible. Such expressionless boring actors! Hopeless.<br /><br />There are some good things about this: Carradine, despite the script, actually gives a very good performance. And there are a few mildly creepy moments involving a ghost of a Great Dane walking through walls. There's also one of the worst-looking knockouts in cinema history. Still, none of this is fun enough to sit through this. Avoid.\")\n",
      "(0, \"I'm a big fan of the TV series Largo Winch. This movie was pain for me. I had to use fast forward not to fell to sleep. It was boring! How can somebody ruin this title so much? The story was the only good thing. Actors were sh.t. They can't live the role. The main actor(Tom ... ) is a null. Watch the other roles of this actor. The fighting scenes were unbelievable boring and not to followable,somehow they were not to follow the situation. Like other reviewer said low budget film with bad actors.Maybe next time somebody else can do better thing out of this title. French can't do right thing with big films,like Alien 4. That was bit brrr, after Alien 1,2,3.\")\n",
      "(0, \"OK we all love the daisy dukes, but what is up with this cast. Lets start, Jessica Simpson as Daisy, there is not one thing country about this girl and Daisy was not ditzy! Uncle Jesse was probably the closest one to resemble the original. No offense to Burt, but I never noticed Boss HOg being so tall. That was part of the humor of Boss Hog was his size. Did they even try someone like Danny Devito?!? OK , now get this they cast Jessica Simpson did anyone take a look at her husband? He matches Luke Duke to a tee!!!!!! Cleary these producers did not look at the appearance of the old cast members. The screen t's were never present on the dukes!! This made the movie a turn off from the beginning. I give this a HUGE thumbs down.\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start=train_iter.pos_inx\n",
    "start=0\n",
    "for i in range(-10,10):\n",
    "    print(train_iter[start+i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following defines the mapping of numeric labels to positive and negative reviews:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive review'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_label = {0: \" negative review\", 1: \"positive review\"}\n",
    "imdb_label[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following checks to make sure that there are exactly 2 classes in the train dataset:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_class = len(set([label for (label, text) in train_iter ]))\n",
    "num_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following are some token indices:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[466, 13077]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab([\"age\",\"hello\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and validate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following converts the dataset into map-style datasets and then performs a random split to create separate training and validation datasets. The training dataset will contain 95% of the samples in the original training set, while the validation dataset will contain the remaining 5%. These datasets can be used for training and evaluating a machine learning model for text classification on the IMDB dataset. The final performance of the model will be evaluated on the hold-out test set:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert the training and testing iterators to map-style datasets.\n",
    "train_dataset = to_map_style_dataset(train_iter)\n",
    "test_dataset = to_map_style_dataset(test_iter)\n",
    "\n",
    "# Determine the number of samples to be used for training and validation (5% for validation).\n",
    "num_train = int(len(train_dataset) * 0.95)\n",
    "\n",
    "# Randomly split the training dataset into training and validation datasets using `random_split`.\n",
    "# The training dataset will contain 95% of the samples, and the validation dataset will contain the remaining 5%.\n",
    "split_train_, split_valid_ = random_split(train_dataset, [num_train, len(train_dataset) - num_train])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code checks if a CUDA-compatible GPU is available in the system using PyTorch, a popular deep learning framework. If a GPU is available, it assigns the device variable to \"cuda\" (which stands for CUDA, the parallel computing platform and application programming interface model developed by NVIDIA). If a GPU is not available, it assigns the device variable to \"cpu\" (which means the code will run on the CPU instead).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In PyTorch, the **`collate_fn`** function is used in conjunction with data loaders to customize the way batches are created from individual samples. The provided code defines a `collate_batch` function in PyTorch, which is used with data loaders to customize batch creation from individual samples. It processes a batch of data, including labels and text sequences. It applies the `text_pipeline` function to preprocess the text. The processed data is then converted into PyTorch tensors and returned as a tuple containing the label tensor, text tensor, and offsets tensor representing the starting positions of each text sequence in the combined tensor. The function also ensures that the returned tensors are moved to the specified device (e.g., GPU) for efficient computation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list = [], []\n",
    "    for _label, _text in batch:\n",
    "        label_list.append(label_pipeline(_label))\n",
    "        text_list.append(torch.tensor(text_pipeline(_text), dtype=torch.int64))\n",
    "\n",
    "\n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    text_list = pad_sequence(text_list, batch_first=True)\n",
    "\n",
    "\n",
    "    return label_list.to(device), text_list.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You convert the dataset objects to a data loader by applying the collate function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    split_train_, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n",
    ")\n",
    "valid_dataloader = DataLoader(\n",
    "    split_valid_, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the what these data loaders generate:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m label,seqence\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalid_dataloader\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m label,seqence\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    676\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    679\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[18], line 7\u001b[0m, in \u001b[0;36mcollate_batch\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _label, _text \u001b[38;5;129;01min\u001b[39;00m batch:\n\u001b[1;32m      6\u001b[0m     label_list\u001b[38;5;241m.\u001b[39mappend(label_pipeline(_label))\n\u001b[0;32m----> 7\u001b[0m     text_list\u001b[38;5;241m.\u001b[39mappend(torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[43mtext_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_text\u001b[49m\u001b[43m)\u001b[49m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mint64))\n\u001b[1;32m     10\u001b[0m label_list \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(label_list, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mint64)\n\u001b[1;32m     11\u001b[0m text_list \u001b[38;5;241m=\u001b[39m pad_sequence(text_list, batch_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m, in \u001b[0;36mtext_pipeline\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtext_pipeline\u001b[39m(x):\n\u001b[0;32m----> 2\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m vocab(\u001b[43mtokenizer\u001b[49m(x))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "label,seqence=next(iter(valid_dataloader ))\n",
    "label,seqence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code defines a class called `TextClassifier` that represents a simple text classifier that uses an embedding layer, a hidden linear layer with a ReLU avtivation, and an output linear layer. The constructor takes the following arguments:\n",
    "\n",
    "- `num_class`: The number of classes to classify.\n",
    "- `freeze`: Whether to freeze the embedding layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class TextClassifier(nn.Module):\n",
    "    def __init__(self, num_classes,freeze=False):\n",
    "        super(TextClassifier, self).__init__()\n",
    "        self.embedding = nn.Embedding.from_pretrained(glove_embedding.vectors.to(device),freeze=freeze)\n",
    "        # An example of adding additional layers: A linear layer and a ReLU activation\n",
    "        self.fc1 = nn.Linear(in_features=100, out_features=128)\n",
    "        self.relu = nn.ReLU()\n",
    "        # The output layer that gives the final probabilities for the classes\n",
    "        self.fc2 = nn.Linear(in_features=128, out_features=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass the input through the embedding layer\n",
    "        x = self.embedding(x)\n",
    "        # Here you can use a simple mean pooling\n",
    "\n",
    "        x = torch.mean(x, dim=1)\n",
    "        # Pass the pooled embeddings through the additional layers\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        return self.fc2(x)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model on the full dataset\n",
    "\n",
    "The model can then be trained on labeled data from the IMDB dataset with two classes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's create the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=TextClassifier(num_classes=2,freeze=True)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code line `predicted_label=model(text, offsets)` is used to obtain predicted labels from a model for a given input text and its corresponding offsets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "predicted_label=model(seqence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following returns the shape of `predicted_label`. Because your dataset iterators are batching 64 inputs, `predicted_label` should return 64 rows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predicted_label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each input, the model outputs two logits corresponding to the two classes in the classification task. If the value of the first logit is greater than the second, the predicted class is class 0, which maps to a negative review. If the second logit is greater than the first, the predicted class is class 1, which maps to a positive review:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following **`predict`** function takes in a text, a text pipeline, and a model as inputs. It uses a pretrained model passed as a parameter to predict the label of the text for text classification on the IMDB dataset:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text, model, text_pipeline):\n",
    "    with torch.no_grad():\n",
    "        text = torch.unsqueeze(torch.tensor(text_pipeline(text)),0).to(device)\n",
    "\n",
    "        output = model(text)\n",
    "        return imdb_label[output.argmax(1).item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(\"the is a good movie\",model,text_pipeline )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can create a function to evaluate the model's accuracy on a dataset:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader, model, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for label, text in dataloader:\n",
    "            label, text = label.to(device), text.to(device)\n",
    "            outputs = model(text)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += label.size(0)\n",
    "            correct += (predicted == label).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following evaluates the performance of your model on the test set:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(test_dataloader , model, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the current performance of the model is no better than average. This outcome is expected, considering that the model has not undergone any training yet.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "\n",
    "The following defines the training function used to train the model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, criterion, train_dataloader, valid_dataloader, epochs=100, model_name=\"my_modeldrop\"):\n",
    "    cum_loss_list = []\n",
    "    acc_epoch = []\n",
    "    best_acc = 0\n",
    "    file_name = model_name\n",
    "    \n",
    "    for epoch in tqdm(range(1, epochs + 1)):\n",
    "        model.train()\n",
    "        cum_loss = 0\n",
    "        for _, (label, text) in enumerate(train_dataloader):            \n",
    "            optimizer.zero_grad()\n",
    "            predicted_label = model(text)\n",
    "            loss = criterion(predicted_label, label)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "            optimizer.step()\n",
    "            cum_loss += loss.item()\n",
    "        #print(\"Loss:\", cum_loss)\n",
    "        cum_loss_list.append(cum_loss)\n",
    "        acc_val = evaluate(valid_dataloader, model, device)\n",
    "        acc_epoch.append(acc_val)\n",
    "        \n",
    "        if acc_val > best_acc:\n",
    "            best_acc = acc_val\n",
    "            print(f\"New best accuracy: {acc_val:.4f}\")\n",
    "            #torch.save(model.state_dict(), f\"{model_name}.pth\")\n",
    "    \n",
    "    #save_list_to_file(cum_loss_list, f\"{model_name}_loss.pkl\")\n",
    "    #save_list_to_file(acc_epoch, f\"{model_name}_acc.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following sets the learning rate (LR) to 1, which determines the step size at which the optimizer updates the model's parameters during training. The CrossEntropyLoss criterion is used to calculate the loss between the model's predicted outputs and the ground truth labels. This loss function is commonly employed for multi-class classification tasks.\n",
    "\n",
    "The chosen optimizer is Stochastic Gradient Descent (SGD), which optimizes the model's parameters based on the computed gradients with respect to the loss function. The SGD optimizer uses the specified learning rate to control the size of the weight updates.\n",
    "\n",
    "Additionally, a learning rate scheduler is defined using StepLR. This scheduler adjusts the learning rate during training, reducing it by a factor (gamma) of 0.1 after every epoch (step) to improve convergence and fine-tune the model's performance. These components together form the essential setup for training a neural network using the specified learning rate, loss criterion, optimizer, and learning rate scheduler.\n",
    "\n",
    "For the sake of time efficiency, the number of epochs has been set to 2. This is to give you a practical demonstration of what the training process looks like. However, if you were to train this model in a real-world scenario, you would likely increase the number of epochs to a larger figure, such as 100 or more. Given the reduced training set defined earlier, it takes approximately 2 minutes to complete 2 epochs of training:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR=1\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have pretrained the model for 300 epochs using a GPU and saved this model for your convenience. However, to demonstrate the training process, the following code has been included that trains the model for just two epochs. Please note that you have limited the number of epochs to two because training on a CPU can be time-consuming. Even with just two epochs, you can expect the following code to run for approximately one minute.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"model_imdb_freeze_true2\"\n",
    "train_model(model, optimizer, criterion, train_dataloader, valid_dataloader, epochs=2, model_name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of evaluating the model trained on 2 epochs, let's load the pretrained model that was trained for 300 epochs:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%%capture \n",
    "!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/ZvhVWJU0flC7BmU1jjYxjg/model-imdb-freeze-true2.pth\n",
    "!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/2RdN-JG4Rm5Gx3UNtOP4NA/model-imdb-freeze-true2-acc.pkl\n",
    "!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/8qoGvWk0BdXRGoFAOT-dAw/model-imdb-freeze-true2-loss.pkl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the cost and accuracy for each epoch for the pretrained model that was trained for 300 epochs. From the plot, it becomes evident that with just a few epochs, the accuracy exhibits significant volatility.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cum_loss_list=load_list_from_file(model_name.replace('_','-') + \"-loss.pkl\")\n",
    "acc_epoch=load_list_from_file(model_name.replace('_','-') + \"-acc.pkl\")\n",
    "plot(cum_loss_list,acc_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, you load the model that has been trained for you. Please comment out these lines if you want to train the model yourself.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(model_name.replace('_','-') + \".pth\", map_location=device))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following evaluates the model on the test data. The pretrained model achieves an accuracy of 66%.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(test_dataloader , model, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Low-Rank Adaptation (LoRA)\n",
    "\n",
    "PyTorch and the Hugging Face library provide robust tools for model manipulation with LoRA, but they are not intuitive. In this section, you delve into building a LoRA (Low-Rank Adaptation) implementation from scratch using PyTorch. LoRA is a general method, but it's commonly applied to the Attention layer. For the sake of simplicity, in this lab, you apply it to a Vanilla neural network. This decision is made because accessing the Attention Parameters in the PyTorch Encoder module can be challenging.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LoRA\n",
    "1) For any arbitrary layer of a network, you have the model with pretrained parameters $ W_0 $, which are the parameters of the model. If you only consider the attention parameters for each layer, at a minimum $ 4 \\times m \\times n$ for each layer. For many models, this can reach in the trillions of learnable parameters. Each time you fine-tune a new dataset, you have to store trillions of parameters.\n",
    "\n",
    "2) $ \\Delta W $ represents two matrices $ B $ and $ A $, where $ B $ and $ A $ are constrained such that $ B \\in \\mathbb{R}^{m \\times r} $, $ A \\in \\mathbb{R}^{r \\times n} $, and $ r \\leq \\min(m, n) $. The total number of parameters is $ A $ and $ B $ is much smaller than $ W_1$  and much easier to store.\n",
    "\n",
    "$ W_1\\approx W_0 + \\Delta  W = W_0 + BA $\n",
    "\n",
    "\n",
    "\n",
    "3) To train and predict, the forward pass holds $W_0$ constant.\n",
    "\n",
    "$h = W_0 + \\Delta W  = W_0x + BAx $\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "To scale $\\Delta W \\times \\dfrac{\\alpha'}{r}$, where $\\alpha$ is a constant in $ r $.  Adjusting $\\alpha'$ is similar to tuning the learning rate if the initialization is properly scaled. Therefore, you set $\\alpha'$ to the first $ r $ you try and do not tune it further; just use $\\alpha$. This scaling reduces the need to retune hyperparameters. The final form is:\n",
    "\n",
    "$h =  W_0x +  \\dfrac{\\alpha'}{r} BAx=  W_0x +  \\alpha BAx $\n",
    "\n",
    "The following example illustrates the process.\n",
    "\n",
    "\n",
    "$\n",
    "W_0 + BA = \n",
    "\\begin{bmatrix}\n",
    "w_{11} & w_{12} & w_{13} & w_{14} \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n",
    "w_{21} & w_{22} & w_{23} & w_{24} \\\\\\\\\\\\\n",
    "w_{31} & w_{32} & w_{33} & w_{34} \\\\\\\\\\\\\n",
    "w_{41} & w_{42} & w_{43} & w_{44} \\\\\\\\\\\\\n",
    "\\end{bmatrix} +\n",
    "\\begin{bmatrix}\n",
    "a_1 \\\\\\\\\\\\\n",
    "a_2 \\\\\\\\\\\\\n",
    "a_3 \\\\\\\\\\\\\n",
    "a_4 \\\\\\\\\\\\\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "b_1 & b_2 & b_3 & b_4 \\\\\\\\\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "This illustrates the product of matrices $ A $ and $ B $, denoted as $ AB $, which can be added to $ W_0 $. However, the resulting matrix $ W_0 + AB $ is limited depending on the dimensions of $ A $ and $ B $. This limitation is due to the concept of rank.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rank\n",
    "The rank of a matrix is the number of dimensions the rows of the matrix \"live in.\"  A square matrix is said to be **full rank** if its <a href='https://en.wikipedia.org/wiki/Rank_(linear_algebra)?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2022-01-01'>rank</a> is equal to the number of its rows or columns. Let's make this idea more intuitive with an example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import Matrix, init_printing,Symbol\n",
    "from numpy.linalg import qr,eig,inv,matrix_rank,inv, norm\n",
    "from scipy.linalg import null_space\n",
    "from sympy import Matrix, init_printing,Symbol\n",
    "init_printing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_matrix_and_subspace(F):\n",
    "    assert F.shape[0] == 3, \"Matrix F must have rows equal to 3 for 3D visualization.\"\n",
    "    \n",
    "    ax = plt.figure().add_subplot(projection='3d')\n",
    "    \n",
    "    # Plot each column vector of F as a point and line from the origin\n",
    "    for i in range(F.shape[1]):\n",
    "        ax.quiver(0, 0, 0, F[0, i], F[1, i], F[2, i], color='blue', arrow_length_ratio=0.1, label=f'Column {i+1}')\n",
    "\n",
    "    if F.shape[1] == 2:\n",
    "        # Calculate the normal to the plane spanned by the columns of F if they are exactly two\n",
    "        normal_vector = np.cross(F[:, 0], F[:, 1])\n",
    "        # Plot the plane\n",
    "        xx, yy = np.meshgrid(np.linspace(-3, 3, 10), np.linspace(-3, 3, 10))\n",
    "        zz = (-normal_vector[0] * xx - normal_vector[1] * yy) / normal_vector[2] if normal_vector[2] != 0 else 0\n",
    "        ax.plot_surface(xx, yy, zz, alpha=0.5, color='green', label='Spanned Plane')\n",
    "\n",
    "    # Set plot limits and labels\n",
    "    ax.set_xlim([-3, 3])\n",
    "    ax.set_ylim([-3, 3])\n",
    "    ax.set_zlim([-3, 3])\n",
    "    ax.set_xlabel('$x_{1}$')\n",
    "    ax.set_ylabel('$x_{2}$')\n",
    "    ax.set_zlabel('$x_{3}$')\n",
    "    #ax.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_matrix_and_subspace(F):\n",
    "    assert F.shape[0] == 3, \"Matrix F must have 3 rows to represent 3D space.\"\n",
    "\n",
    "    ax = plt.figure().add_subplot(projection='3d')\n",
    "    \n",
    "    # Plot each column vector of F\n",
    "    for i in range(F.shape[1]):\n",
    "        ax.quiver(0, 0, 0, F[0, i], F[1, i], F[2, i], color='blue', arrow_length_ratio=0.1, label=f'Column {i+1}')\n",
    "\n",
    "    # Calculate the null space of the transpose of F\n",
    "    normal_vector = null_space(F.T)\n",
    "    \n",
    "    # Check that the null space is 1-dimensional\n",
    "    if normal_vector.shape[1] == 1:\n",
    "        normal_vector = normal_vector[:, 0]  # Simplify the array to 1D\n",
    "        # Create a meshgrid for the plane\n",
    "        xx, yy = np.meshgrid(np.linspace(-3, 3, 10), np.linspace(-3, 3, 10))\n",
    "        # Calculate corresponding z coordinates based on the plane equation ax + by + cz = 0\n",
    "        zz = (-normal_vector[0] * xx - normal_vector[1] * yy) / normal_vector[2] if normal_vector[2] != 0 else 0\n",
    "        ax.plot_surface(xx, yy, zz, alpha=0.5, color='green', label='Spanned Plane')\n",
    "    else:\n",
    "        print(\"The null space is not 1-dimensional, so a unique plane cannot be determined.\")\n",
    "\n",
    "    # Set plot limits and labels\n",
    "    ax.set_xlim([-3, 3])\n",
    "    ax.set_ylim([-3, 3])\n",
    "    ax.set_zlim([-3, 3])\n",
    "    ax.set_xlabel('X axis')\n",
    "    ax.set_ylabel('Y axis')\n",
    "    ax.set_zlabel('Z axis')\n",
    "    #ax.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the context of Low-Rank Adaptation (LoRA), where $B \\in \\mathbb{R}^{d \\times r}$, the matrix $B$:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B=torch.tensor([[1,0],[0,1],[0,0]]).numpy()\n",
    "\n",
    "Matrix(B)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This $3 \\times 2$ matrix has columns that span a 2-dimensional subspace in $\\mathbb{R}^3$. Specifically, the columns of $B$ are:\n",
    "\n",
    "- $\\mathbf{b}_1 = \\begin{bmatrix} 1 \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ 0 \\\\ 0 \\end{bmatrix}$\n",
    "- $\\mathbf{b}_2 = \\begin{bmatrix} 0 \\\\\\\\ 1 \\\\ 0 \\end{bmatrix}$\n",
    "\n",
    "These columns are standard basis vectors for the $xy$-plane in $\\mathbb{R}^3$, and, thus, they span the $xy$-plane shown in green in the following image. Muliplying each column vector in blue by a scaler always falls in the plane.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " plot_matrix_and_subspace(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this scenario, the vectors, despite each having three components, can reach any point on the two-dimensional green plane depicted in the image. These vectors span the green plane, which resides within a two-dimensional subspace. This subspace's dimension, also known as its 'rank', is two—corresponding to the dimensionality of the plane. If the rank were three, any point in the 3D space could be reached by some combination of the columns of $𝐵$. The rank of a matrix can be determined by using the matrix_rank function provided by NumPy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_rank(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, you plot a different matrix where the matrix spans a different plane, but the rank remains two.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_=torch.tensor([[1,0],[-2,1],[0,1]]).numpy()\n",
    "plot_matrix_and_subspace(B_)\n",
    "print(\"rank of B\",matrix_rank(B_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_rank(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, you present the matrix ```A```. The rank of this matrix is also two.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A=torch.tensor([[1,1,-1,1,0],[-2,2,2,0,1]]).numpy()\n",
    "Matrix(A)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_rank(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the matrices $ C = BA $, if $B $ and $ A $ both have a rank of $ r $:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C=B@A\n",
    "Matrix(C)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The columns of $ C $ will have the same rank as $ B $. Furthermore, the span of the columns of $ C $ will be the same as the span of the columns of $ B $.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"rank of C\",matrix_rank(C))\n",
    "plot_matrix_and_subspace(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding LoRA in PyTorch\n",
    "\n",
    "LoRA (Low-Rank Adaptation) is relatively simple to initialize in PyTorch. You initialize LoRA with the dimensions of the input (`in_dim`), $ m $, output (`out_dim`), $n $, a rank (`rank`), $ r $, and a scaling factor `alpha`. The parameters are initialized as follows:\n",
    "\n",
    "```\n",
    "self.A = torch.nn.Parameter(torch.randn(in_dim, rank) * std_dev)\n",
    "self.B = torch.nn.Parameter(torch.zeros(rank, out_dim))\n",
    "```\n",
    "\n",
    "The use of  ```nn.Parameter``` makes these values learnable parameters.\n",
    "\n",
    "In the forward function, LoRA uses the notation $BAx$ PyTorch, the input vector is a row, so the output becomes $x^TA^TB^T$ will drop the trapose from now on. The forward pass is implemented as:\n",
    "```\n",
    "x = self.alpha * (x @ self.A @ self.B)\n",
    "```\n",
    "The use of  ```nn.Parameter``` makes these values learnable parameters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoRALayer(torch.nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, rank, alpha):\n",
    "        super().__init__()\n",
    "        std_dev = 1 / torch.sqrt(torch.tensor(rank).float())\n",
    "        self.A = torch.nn.Parameter(torch.randn(in_dim, rank) * std_dev)\n",
    "        \n",
    "        self.B = torch.nn.Parameter(torch.zeros(rank, out_dim))\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.alpha * (x @ self.A @ self.B)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class ```LinearWithLoRA```  copies the original linear model and creates a ```LoRALayer``` object. \n",
    "```\n",
    "self.linear = linear.to(device)\n",
    " self.lora = LoRALayer(\n",
    "            linear.in_features, linear.out_features, rank, alpha\n",
    "        ).to(device)\n",
    "```\n",
    "\n",
    "Then, in the forward method apply both the original linear model and the output Lora model to the input x and add them together ```self.linear(x) + self.lora(x)```. This corresponds to:\n",
    "\n",
    " $xW_0 + xAB $\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearWithLoRA(torch.nn.Module):\n",
    "    def __init__(self, linear, rank, alpha):\n",
    "        super().__init__()\n",
    "        self.linear = linear.to(device)\n",
    "        self.lora = LoRALayer(\n",
    "            linear.in_features, linear.out_features, rank, alpha\n",
    "        ).to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        return self.linear(x) + self.lora(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying LoRA\n",
    "To fine-tune with LoRA, first, load a pretrained TextClassifier model with LoRA (while freezing its layers), load its pretrained state from a file, and then disable gradient updates for all of its parameters to prevent further training. Here, you will load a model that was pretrained on the AG NEWS dataset, which is a dataset that has 4 classes. Note that when you initialize this model, you set `num_classes` to 4. Moreover, the pretrained AG_News model was trained with the embedding layer unfrozen. Hence you will initialize the model with `freeze=False`. Although you are initializing the model with layers unfrozen and the wrong number of classes for your task, you will make modifications to the model later on that correct this:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "import io\n",
    "\n",
    "model_lora=TextClassifier(num_classes=4,freeze=False)\n",
    "model_lora.to(device)\n",
    "\n",
    "urlopened = urlopen('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/uGC04Pom651hQs1XrZ0NsQ/my-model-freeze-false.pth')\n",
    "\n",
    "stream = io.BytesIO(urlopened.read())\n",
    "state_dict = torch.load(stream, map_location=device)\n",
    "model_lora.load_state_dict(state_dict)\n",
    "\n",
    "# Here, you freeze all layers:\n",
    "for parm in model_lora.parameters():\n",
    "    parm.requires_grad=False\n",
    "model_lora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the `for` loop in the above code froze all of the layers in the neural network, including the embedding layer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, note that the original model was on a classification problem that had four classes, while the IMDB dataset has just 2 classes. To account for this, you will replace the final layer with a new linear layer where the number of outputs equals 2:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lora.fc2=nn.Linear(in_features=128, out_features=2, bias=True).to(device)\n",
    "model_lora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's view all of the modules in the object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your task now is to replace the hidden layer with a LoRA layer. You can access the hidden layer as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lora.fc1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following replaces this layer with a LoRA layer:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lora.fc1=LinearWithLoRA(model_lora.fc1,rank=2, alpha=0.1).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the hidden layer again to ensure that it is indeed converted to a LoRA layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lora.fc1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, training the model is similar, with the only difference being that, except for the output layer, only the learnable parameters \n",
    "```A``` and  ```B``` will be updated. The code to select the values for  `r` and `alpha`, which is not run, is nonetheless provided herein for your convenience.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lora.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Click here to see code to select r and alpha</b></summary>\n",
    "    \n",
    "```python \n",
    "ranks = [1, 2, 5, 10]\n",
    "alphas = [0.1, 0.5, 1.0, 2.0, 5.0]\n",
    "\n",
    "results=[]\n",
    "accuracy_old=0\n",
    "# Loop over each combination of 'r' and 'alpha'\n",
    "for r in ranks:\n",
    "    for alpha in alphas:\n",
    "        print(f\"Testing with rank = {r} and alpha = {alpha}\")\n",
    "        model_name=f\"model_lora_rank{r}_alpha{alpha}_AGtoIBDM_final_adam_\"\n",
    "        \n",
    "        model_lora=TextClassifier(num_classes=4,freeze=False)\n",
    "        model_lora.to(device)\n",
    "        \n",
    "        urlopened = urlopen('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/uGC04Pom651hQs1XrZ0NsQ/my-model-freeze-false.pth')\n",
    "        \n",
    "        stream = io.BytesIO(urlopened.read())\n",
    "        state_dict = torch.load(stream, map_location=device)\n",
    "        model_lora.load_state_dict(state_dict)\n",
    "        \n",
    "        for parm in model_lora.parameters():\n",
    "            parm.requires_grad=False\n",
    "        \n",
    "        model_lora.fc2=nn.Linear(in_features=128, out_features=2, bias=True)\n",
    "        model_lora.fc1=LinearWithLoRA(model_lora.fc1,rank=r, alpha=alpha )\n",
    "        optimizer = torch.optim.Adam(model_lora.parameters(), lr=LR)\n",
    "\n",
    "        scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.1)\n",
    "        \n",
    "        model_lora.to(device)\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        train_model(model_lora, optimizer, criterion, train_dataloader, valid_dataloader, epochs=300, model_name=model_name)\n",
    "        \n",
    "        accuracy=evaluate(valid_dataloader ,  model_lora, device)\n",
    "        result = {\n",
    "            'rank': r,\n",
    "            'alpha': alpha,\n",
    "            'accuracy':accuracy\n",
    "        }\n",
    "\n",
    "        # Append the dictionary to the results list\n",
    "        results.append(result)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        if accuracy>accuracy_old:\n",
    "            print(f\"Testing with rank = {r} and alpha = {alpha}\")\n",
    "            print(f\"accuracy: {accuracy} accuracy_old: {accuracy_old}\" )\n",
    "            accuracy_old=accuracy\n",
    "            torch.save(model.state_dict(), f\"{model_name}.pth\")\n",
    "            save_list_to_file(cum_loss_list, f\"{model_name}_loss.pkl\")\n",
    "            save_list_to_file(acc_epoch, f\"{model_name}_acc.pkl\")\n",
    "            \n",
    "        \n",
    "```       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Let's set up the training components for the `model_lora` model, defining a learning rate of 1, using cross-entropy loss as the criterion, optimizing with stochastic gradient descent (SGD), and scheduling the learning rate to decay by a factor of 0.1 at each epoch:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR=1\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model_lora.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have pretrained a model using an identical procedure for 300 epochs and saved it for your convenience. However, to give you a taste of how training works in practice, run the following code to train the model for just 2 epochs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"model_lora_final2\"\n",
    "train_model(model_lora,optimizer, criterion, train_dataloader, valid_dataloader, epochs=2, model_name=model_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of evaluating the model you just trained for 2 epochs, lets have a look at the LoRA model pretrained on 300 epochs:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%%capture \n",
    "!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/JWPRb1RMhKLRMUWOKw9pxA/model-lora-final2.pth\n",
    "!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/_dm02rLyTrwsXEQh2r32sQ/model-lora-final2-acc.pkl\n",
    "!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/OZbVqKjoqOSIwnET8AB1KA/model-lora-final2-loss.pkl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following shows the progression of the training of this model for 300 epochs:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cum_loss_list=load_list_from_file(model_name.replace('_','-') + \"-loss.pkl\")\n",
    "acc_epoch=load_list_from_file(model_name.replace('_','-') + \"-acc.pkl\")\n",
    "plot(cum_loss_list,acc_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load actually load the model into model_lora:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lora.load_state_dict(torch.load(model_name.replace('_','-') + \".pth\", map_location=device))\n",
    "model_lora.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, let's evaluate its performance on the test data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(test_dataloader , model_lora, device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You get a 3% improvement over a model trained from scratch by using LoRA. Note that this occurs despite the fact that the model fine-tuned with LoRA updated less parameters than the model trained from scratch!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ```model_lora.fc1``` attribute represents ```LinearWithLoRA``` which contains both the standard ```Linear``` layer ``(linear)`` and an additional ```LoRA``` layer ```(lora)``` which represents the ```LoRALayer```.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lora.fc1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From ```model_lora.fc1.lora```, you can obtain the learnable parameters A and B.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B=model_lora.fc1.lora.B\n",
    "print(\"B\",B)\n",
    "print(\"\\n Number of elements in the tensor B\",B.numel())\n",
    "torch.save(B, 'B.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A=model_lora.fc1.lora.A\n",
    "print(\"A\",A)\n",
    "print(\"\\n Number of elements in the tensor A\",A.numel())\n",
    "torch.save(A, 'A.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A and B have approximately 450 parameters. If you were to store the entire linear layer, you would have 12,800 parameters, which is around 28 times more. Remember, this is possibly the simplest model that you can have.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\n Number of elements in the tensor A\",model_lora.fc1.linear.weight.numel())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " alfa and the ouput layer  are also saved.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alfa_=model_lora.fc1.lora.alpha\n",
    "torch.save(alfa_, 'alfa_.pth')\n",
    "torch.save(model_lora.fc2.state_dict(), 'out_layer.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the model\n",
    "\n",
    "The main advantage of LoRA is that for fine-tuning, you only need to save the learnable parameters A and B, alpha, and the output layer in your classification example.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The saved files are converted to tensors and the linear layer, respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.load('A.pth')\n",
    "print(\"A:\",A.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = torch.load('B.pth')\n",
    "print(\"B:\",B.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alfa_ = torch.load('alfa_.pth')\n",
    "alfa_ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output layer:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_layer=nn.Linear(in_features=128, out_features=2, bias=True)\n",
    "output_layer.load_state_dict(torch.load('out_layer.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model object is created and the pretrained parameters are loaded:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_load_lora = TextClassifier(num_classes=4,freeze=False)\n",
    "model_load_lora.to(device)\n",
    "\n",
    "urlopened = urlopen('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/uGC04Pom651hQs1XrZ0NsQ/my-model-freeze-false.pth')\n",
    "\n",
    "stream = io.BytesIO(urlopened.read())\n",
    "state_dict = torch.load(stream, map_location=device)\n",
    "model_load_lora.load_state_dict(state_dict)\n",
    "\n",
    "model_load_lora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LoRA layer object is added to the original hidden layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_load_lora.fc1=LinearWithLoRA(model_load_lora.fc1,rank=2, alpha=0.1)\n",
    "model_load_lora.fc2=nn.Linear(in_features=128, out_features=2, bias=True).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters from fine-tuning are added.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_load_lora.fc1.lora.A=A\n",
    "model_load_lora.fc1.lora.B=B\n",
    "model_load_lora.fc1.lora.alpha=alfa_ \n",
    "model_load_lora.fc2=output_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_load_lora.to(device)\n",
    "model_load_lora.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(test_dataloader , model_load_lora, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This confirms that the model loaded correctly. You still get a 3% improvement in accuracy!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the following shows how you can make a prediction on the following article using the function **`predict`**:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article=\"\"\"This was a lacklustre movie with very little going for it. I was not impressed.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This markdown content generates a styled box with light gray background and padding. It contains an `<h3>` header displaying the content of the `article` variable, and an `<h4>` header indicating the predicted category of the news article which is provided by the `result` variable. The placeholders `{article}` and `{result}` will be dynamically replaced with actual values when this markdown is rendered.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = predict(article, model_load_lora, text_pipeline)\n",
    "\n",
    "markdown_content = f'''\n",
    "<div style=\"background-color: lightgray; padding: 10px;\">\n",
    "    <h3>{article}</h3>\n",
    "    <h4>The category of the news article: {result}</h4>\n",
    "</div>\n",
    "'''\n",
    "\n",
    "md(markdown_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise: Apply LoRA to a different network\n",
    "\n",
    "The following code defines a neural network called `NNet`. \n",
    "\n",
    "`NNet` is a neural network that was originally written to identify hand-written digits from 32x32 images. Your task is to fine-tune this network to perform letter recognition using LoRA by replacing the section labeled `### REPLACE THIS ###` in the code block below. To enhance your understanding, apply LoRA to just the second linear layer, and replace the last layer with a layer that has 26 outputs, one for each letter in the English alphabet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for the solution</summary>\n",
    "\n",
    "```python\n",
    "class NNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(NNet, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)  # 5*5 from image dimension\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, input):\n",
    "        # Convolution layer C1: 1 input image channel, 6 output channels,\n",
    "        # 5x5 square convolution, it uses RELU activation function, and\n",
    "        # outputs a Tensor with size (N, 6, 28, 28), where N is the size of the batch\n",
    "        c1 = F.relu(self.conv1(input))\n",
    "        # Subsampling layer S2: 2x2 grid, purely functional,\n",
    "        # this layer does not have any parameter, and outputs a (N, 6, 14, 14) Tensor\n",
    "        s2 = F.max_pool2d(c1, (2, 2))\n",
    "        # Convolution layer C3: 6 input channels, 16 output channels,\n",
    "        # 5x5 square convolution, it uses RELU activation function, and\n",
    "        # outputs a (N, 16, 10, 10) Tensor\n",
    "        c3 = F.relu(self.conv2(s2))\n",
    "        # Subsampling layer S4: 2x2 grid, purely functional,\n",
    "        # this layer does not have any parameter, and outputs a (N, 16, 5, 5) Tensor\n",
    "        s4 = F.max_pool2d(c3, 2)\n",
    "        # Flatten operation: purely functional, outputs a (N, 400) Tensor\n",
    "        s4 = torch.flatten(s4, 1)\n",
    "        # Fully connected layer F5: (N, 400) Tensor input,\n",
    "        # and outputs a (N, 120) Tensor, it uses RELU activation function\n",
    "        f5 = F.relu(self.fc1(s4))\n",
    "        # Fully connected layer F6: (N, 120) Tensor input,\n",
    "        # and outputs a (N, 84) Tensor, it uses RELU activation function\n",
    "        f6 = F.relu(self.fc2(f5))\n",
    "        # Gaussian layer OUTPUT: (N, 84) Tensor input, and\n",
    "        # outputs a (N, 10) Tensor\n",
    "        output = self.fc3(f6)\n",
    "        return output\n",
    "\n",
    "model_exercise = NNet()\n",
    "model_exercise.to(device)\n",
    "\n",
    "print('This is what the model looked like before applying LoRA:')\n",
    "print(model_exercise)\n",
    "print(\"\\n###############\\n\")\n",
    "\n",
    "# Freeze all parameters:\n",
    "for parm in model_exercise.parameters():\n",
    "    parm.requires_grad=False\n",
    "\n",
    "# Change final layer for one with 26 outputs:\n",
    "model_exercise.fc3=nn.Linear(in_features=84, out_features=26, bias=True).to(device)\n",
    "\n",
    "# Apply LoRA to the second linear layer\n",
    "model_exercise.fc2=LinearWithLoRA(model_exercise.fc2,rank=2, alpha=0.1).to(device)\n",
    "\n",
    "print('This is what the model looked like after applying LoRA:')\n",
    "print(model_exercise)\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations! You have completed the lab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Joseph Santarcangelo](https://author.skills.network/instructors/joseph_santarcangelo) has a Ph.D. in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his Ph.D.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Wojciech \"Victor\" Fulmyk](https://www.linkedin.com/in/wfulmyk) is a Data Scientist at IBM, and a PhD Candidate in economics at the University of Calgary.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Ashutosh Sagar](https://www.linkedin.com/in/ashutoshsagar/) is completing his MS in CS from Dalhousie University. He has previous experience working with Natural Language Processing and as a Data Scientist.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[Finetuning with LoRA -- A Hands-On Example](https://lightning.ai/lightning-ai/studios/code-lora-from-scratch)\n",
    "\n",
    "[TEXT CLASSIFICATION WITH THE TORCHTEXT LIBRARY](https://pytorch.org/tutorials/beginner/text_sentiment_ngrams_tutorial.html)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{## Change Log}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{|Date (YYYY-MM-DD)|Version|Changed By|Change Description||-|-|-|-||2023-07-27|0.1|Joseph|Created Lab||2024-06-04|1.0|wfulmyk|First release|}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "© Copyright IBM Corporation. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "prev_pub_hash": "6c8e55310339c75d5fbdc4074bcdd58bbecf9469db6b8b2e40bdf1395c8690df"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
